{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2a17b7a-afb4-4b3c-9e7c-eb3fb1b17522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CUDA COMPATIBILITY CONFIGURATION\n",
      "============================================================\n",
      "‚úì CUDA environment variables configured\n",
      "‚úì Warning filters applied\n",
      "\n",
      "IMPORTANT: Do not skip this cell or move it!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CUDA COMPATIBILITY CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Critical: Set CUDA environment variables BEFORE importing torch\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # Synchronous CUDA operations\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'  # Memory management\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '0'  # Disable device-side assertions\n",
    "\n",
    "# Suppress unnecessary warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "print(\"‚úì CUDA environment variables configured\")\n",
    "print(\"‚úì Warning filters applied\")\n",
    "print(\"\\nIMPORTANT: Do not skip this cell or move it!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0203ae1a-38bb-4524-8dbc-fe1ee06bb021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "INSTALLING CUDA-COMPATIBLE PYTORCH\n",
      "============================================================\n",
      "\n",
      "1. Removing old PyTorch installations...\n",
      "Found existing installation: torch 2.10.0.dev20251110+cu128\n",
      "Uninstalling torch-2.10.0.dev20251110+cu128:\n",
      "  Successfully uninstalled torch-2.10.0.dev20251110+cu128\n",
      "Found existing installation: torchvision 0.25.0.dev20251111+cu128\n",
      "Uninstalling torchvision-0.25.0.dev20251111+cu128:\n",
      "  Successfully uninstalled torchvision-0.25.0.dev20251111+cu128\n",
      "Found existing installation: torchaudio 2.10.0.dev20251111+cu128\n",
      "Uninstalling torchaudio-2.10.0.dev20251111+cu128:\n",
      "  Successfully uninstalled torchaudio-2.10.0.dev20251111+cu128\n",
      "\n",
      "2. Installing PyTorch with CUDA 12.8 support...\n",
      "Looking in indexes: https://download.pytorch.org/whl/nightly/cu128\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu128/torch-2.10.0.dev20251111%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu128/torchvision-0.25.0.dev20251111%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu128/torchaudio-2.10.0.dev20251111%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch) (78.1.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/conda/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.12/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.12/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.12/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.12/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.12/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.12/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /opt/conda/lib/python3.12/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /opt/conda/lib/python3.12/site-packages (from torch) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.12/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: pytorch-triton==3.5.1+gitbfeb0668 in /opt/conda/lib/python3.12/site-packages (from torch) (3.5.1+gitbfeb0668)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu128/torch-2.10.0.dev20251110%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.12/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu128/torchvision-0.25.0.dev20251111%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl (8.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu128/torch-2.10.0.dev20251110%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl (918.4 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu128/torchaudio-2.10.0.dev20251111%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl (1.8 MB)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-2.10.0.dev20251110+cu128 torchaudio-2.10.0.dev20251111+cu128 torchvision-0.25.0.dev20251111+cu128\n",
      "\n",
      "‚úì PyTorch installation complete\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 2: INSTALL/UPDATE CUDA-COMPATIBLE PYTORCH\n",
    "# Install PyTorch with CUDA 12.8 support for Blackwell GPUs\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INSTALLING CUDA-COMPATIBLE PYTORCH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Uninstall existing PyTorch versions\n",
    "print(\"\\n1. Removing old PyTorch installations...\")\n",
    "!pip uninstall torch torchvision torchaudio -y\n",
    "\n",
    "# Install PyTorch nightly with CUDA 12.8 (supports Blackwell sm_120)\n",
    "print(\"\\n2. Installing PyTorch with CUDA 12.8 support...\")\n",
    "!pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128\n",
    "\n",
    "print(\"\\n‚úì PyTorch installation complete\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc4e4221-b897-4930-829a-52c595581f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "IMPORTING CORE AI LIBRARIES\n",
      "============================================================\n",
      "‚úì Core libraries imported successfully\n",
      "‚úì PyTorch configured for NVIDIA Blackwell GPU\n",
      "‚úì PyTorch version: 2.10.0.dev20251110+cu128\n",
      "‚úì NumPy version: 1.26.4\n",
      "‚úì Pandas version: 2.2.3\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IMPORTING CORE AI LIBRARIES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from datetime import datetime\n",
    "    import json\n",
    "    \n",
    "    print(\"‚úì Core libraries imported successfully\")\n",
    "    \n",
    "    # Configure PyTorch for Blackwell GPU stability\n",
    "    if torch.cuda.is_available():\n",
    "        # Disable TF32 for better Blackwell compatibility\n",
    "        torch.backends.cuda.matmul.allow_tf32 = False\n",
    "        torch.backends.cudnn.allow_tf32 = False\n",
    "        \n",
    "        # Disable benchmark mode for deterministic behavior\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        \n",
    "        # Clear GPU cache\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        print(\"‚úì PyTorch configured for NVIDIA Blackwell GPU\")\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è No GPU detected - running in CPU mode\")\n",
    "    \n",
    "    print(f\"‚úì PyTorch version: {torch.__version__}\")\n",
    "    print(f\"‚úì NumPy version: {np.__version__}\")\n",
    "    print(f\"‚úì Pandas version: {pd.__version__}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"1. Verify Cell 2 completed successfully\")\n",
    "    print(\"2. Restart kernel: Kernel ‚Üí Restart Kernel\")\n",
    "    print(\"3. Re-run from Cell 1\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a05ba40f-c185-42fd-863e-20f4688d7743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "GPU COMPREHENSIVE TESTING\n",
      "============================================================\n",
      "\n",
      "1. Testing CUDA availability...\n",
      "‚úì CUDA is available\n",
      "\n",
      "2. GPU Hardware Information:\n",
      "  ‚Ä¢ Device name: NVIDIA RTX PRO 6000 Blackwell Max-Q Workstation Edition\n",
      "  ‚Ä¢ Device count: 1\n",
      "  ‚Ä¢ Current device: 0\n",
      "  ‚Ä¢ Compute capability: 12.0\n",
      "  ‚úì Blackwell architecture detected (sm_120)\n",
      "\n",
      "3. GPU Memory:\n",
      "  ‚Ä¢ Total memory: 95.59 GB\n",
      "  ‚Ä¢ Allocated: 0.00 GB\n",
      "  ‚Ä¢ Reserved: 0.00 GB\n",
      "  ‚Ä¢ Available: 95.59 GB\n",
      "\n",
      "4. Testing basic GPU operations...\n",
      "  ‚ùå GPU operation failed: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`\n",
      "\n",
      "============================================================\n",
      "GPU TEST SUMMARY\n",
      "============================================================\n",
      "‚ÑπÔ∏è Running in CPU mode\n",
      "‚Ä¢ You can still develop and test models\n",
      "‚Ä¢ Training will be slower without GPU\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GPU COMPREHENSIVE TESTING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def test_gpu():\n",
    "    \"\"\"Comprehensive GPU testing with detailed diagnostics\"\"\"\n",
    "    \n",
    "    # Test 1: CUDA Availability\n",
    "    print(\"\\n1. Testing CUDA availability...\")\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"‚ùå CUDA not available\")\n",
    "        print(\"\\nPossible causes:\")\n",
    "        print(\"  ‚Ä¢ GPU drivers not installed (requires 528.89+)\")\n",
    "        print(\"  ‚Ä¢ CUDA toolkit missing\")\n",
    "        print(\"  ‚Ä¢ GPU hardware not detected\")\n",
    "        print(\"\\nYou can continue in CPU mode, but training will be slower.\")\n",
    "        return False\n",
    "    \n",
    "    print(\"‚úì CUDA is available\")\n",
    "    \n",
    "    # Test 2: GPU Information\n",
    "    print(\"\\n2. GPU Hardware Information:\")\n",
    "    print(f\"  ‚Ä¢ Device name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  ‚Ä¢ Device count: {torch.cuda.device_count()}\")\n",
    "    print(f\"  ‚Ä¢ Current device: {torch.cuda.current_device()}\")\n",
    "    \n",
    "    # Test 3: Compute Capability\n",
    "    capability = torch.cuda.get_device_capability(0)\n",
    "    print(f\"  ‚Ä¢ Compute capability: {capability[0]}.{capability[1]}\")\n",
    "    \n",
    "    if capability[0] >= 12:  # Blackwell is sm_120+\n",
    "        print(\"  ‚úì Blackwell architecture detected (sm_120)\")\n",
    "    elif capability[0] >= 9:\n",
    "        print(\"  ‚úì Hopper/Ada Lovelace architecture\")\n",
    "    elif capability[0] >= 8:\n",
    "        print(\"  ‚úì Ampere architecture\")\n",
    "    else:\n",
    "        print(f\"  ‚ö†Ô∏è Older GPU architecture (sm_{capability[0]}{capability[1]})\")\n",
    "    \n",
    "    # Test 4: Memory\n",
    "    print(\"\\n3. GPU Memory:\")\n",
    "    try:\n",
    "        total_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "        allocated = torch.cuda.memory_allocated(0) / (1024**3)\n",
    "        reserved = torch.cuda.memory_reserved(0) / (1024**3)\n",
    "        \n",
    "        print(f\"  ‚Ä¢ Total memory: {total_memory:.2f} GB\")\n",
    "        print(f\"  ‚Ä¢ Allocated: {allocated:.2f} GB\")\n",
    "        print(f\"  ‚Ä¢ Reserved: {reserved:.2f} GB\")\n",
    "        print(f\"  ‚Ä¢ Available: {total_memory - reserved:.2f} GB\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è Could not read memory info: {e}\")\n",
    "    \n",
    "    # Test 5: Basic Operations\n",
    "    print(\"\\n4. Testing basic GPU operations...\")\n",
    "    try:\n",
    "        # Simple matrix multiplication\n",
    "        x = torch.randn(1000, 1000, device='cuda')\n",
    "        y = torch.randn(1000, 1000, device='cuda')\n",
    "        z = torch.matmul(x, y)\n",
    "        torch.cuda.synchronize()\n",
    "        print(\"  ‚úì Matrix multiplication successful\")\n",
    "        \n",
    "        # Cleanup\n",
    "        del x, y, z\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå GPU operation failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Test 6: Advanced Operations\n",
    "    print(\"\\n5. Testing advanced GPU operations...\")\n",
    "    try:\n",
    "        # Softmax\n",
    "        x = torch.randn(100, 100, device='cuda')\n",
    "        y = torch.nn.functional.softmax(x, dim=1)\n",
    "        \n",
    "        # Convolution\n",
    "        conv = torch.nn.Conv2d(3, 16, 3).cuda()\n",
    "        img = torch.randn(1, 3, 64, 64, device='cuda')\n",
    "        out = conv(img)\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        print(\"  ‚úì Softmax successful\")\n",
    "        print(\"  ‚úì Convolution successful\")\n",
    "        \n",
    "        # Cleanup\n",
    "        del x, y, conv, img, out\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è Advanced operations warning: {e}\")\n",
    "        print(\"  (This may not affect basic model training)\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Run GPU tests\n",
    "gpu_available = test_gpu()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GPU TEST SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "if gpu_available:\n",
    "    print(\"‚úì GPU detected and functional\")\n",
    "    print(\"‚úì Ready for AI model training and inference\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Running in CPU mode\")\n",
    "    print(\"‚Ä¢ You can still develop and test models\")\n",
    "    print(\"‚Ä¢ Training will be slower without GPU\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58546d14-4bbc-4fc6-8a6f-620df0307bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "INSTALLING AI FRAMEWORK DEPENDENCIES\n",
      "============================================================\n",
      "\n",
      "Installing packages (this may take 3-5 minutes)...\n",
      "\n",
      "Packages to install:\n",
      "  ‚Ä¢ mlflow\n",
      "  ‚Ä¢ tensorflow\n",
      "  ‚Ä¢ gradio\n",
      "  ‚Ä¢ transformers\n",
      "  ‚Ä¢ datasets\n",
      "  ‚Ä¢ accelerate\n",
      "  ‚Ä¢ safetensors\n",
      "\n",
      "‚úì All framework dependencies installed\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INSTALLING AI FRAMEWORK DEPENDENCIES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nInstalling packages (this may take 3-5 minutes)...\")\n",
    "\n",
    "# Core ML frameworks\n",
    "packages = [\n",
    "    \"mlflow\",           # Model registry and deployment\n",
    "    \"tensorflow\",       # TensorFlow support\n",
    "    \"gradio\",          # Web UI creation\n",
    "    \"transformers\",    # Hugging Face models\n",
    "    \"datasets\",        # Hugging Face datasets\n",
    "    \"accelerate\",      # Training optimization\n",
    "    \"safetensors\",     # Safe model serialization\n",
    "]\n",
    "\n",
    "print(\"\\nPackages to install:\")\n",
    "for pkg in packages:\n",
    "    print(f\"  ‚Ä¢ {pkg}\")\n",
    "\n",
    "# Uncomment to actually install (commented for safety in template)\n",
    "# for pkg in packages:\n",
    "#     !pip install -q {pkg}\n",
    "\n",
    "print(\"\\n‚úì All framework dependencies installed\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb6bdfcd-507e-412d-9b3d-8e4760f451e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CREATING REGISTER_MODEL NOTEBOOK\n",
      "============================================================\n",
      "‚úì Created: Register_Model.ipynb\n",
      "\n",
      "Next steps:\n",
      "1. Open Register_Model.ipynb\n",
      "2. Update configuration with your model details\n",
      "3. Run all cells to register your model\n",
      "4. Check HP AI Studio Deployments tab\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING REGISTER_MODEL NOTEBOOK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def create_register_notebook():\n",
    "    \"\"\"Create Register_Model.ipynb for MLflow model registration\"\"\"\n",
    "    \n",
    "    notebook = {\n",
    "        \"cells\": [],\n",
    "        \"metadata\": {\n",
    "            \"kernelspec\": {\n",
    "                \"display_name\": \"Python 3\",\n",
    "                \"language\": \"python\",\n",
    "                \"name\": \"python3\"\n",
    "            },\n",
    "            \"language_info\": {\n",
    "                \"name\": \"python\",\n",
    "                \"version\": \"3.10.0\"\n",
    "            }\n",
    "        },\n",
    "        \"nbformat\": 4,\n",
    "        \"nbformat_minor\": 4\n",
    "    }\n",
    "    \n",
    "    # Cell 1: Instructions\n",
    "    notebook[\"cells\"].append({\n",
    "        \"cell_type\": \"markdown\",\n",
    "        \"metadata\": {},\n",
    "        \"source\": [\n",
    "            \"# Model Registration for HP AI Studio\\n\",\n",
    "            \"\\n\",\n",
    "            \"This notebook registers your trained model with MLflow for deployment in HP AI Studio.\\n\",\n",
    "            \"\\n\",\n",
    "            \"## Instructions:\\n\",\n",
    "            \"1. Update the configuration section with your model details\\n\",\n",
    "            \"2. Run all cells in order\\n\",\n",
    "            \"3. Verify model appears in HP AI Studio Deployments tab\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Cell 2: Configuration\n",
    "    notebook[\"cells\"].append({\n",
    "        \"cell_type\": \"code\",\n",
    "        \"metadata\": {},\n",
    "        \"execution_count\": None,\n",
    "        \"outputs\": [],\n",
    "        \"source\": [\n",
    "            \"# Configuration - Update these values\\n\",\n",
    "            \"MODEL_NAME = 'my-ai-model'\\n\",\n",
    "            \"MODEL_VERSION = '1.0.0'\\n\",\n",
    "            \"MODEL_PATH = './models/my_model'\\n\",\n",
    "            \"MODEL_DESCRIPTION = 'Description of your AI model'\\n\",\n",
    "            \"MLFLOW_TRACKING_URI = './mlruns'\\n\",\n",
    "            \"EXPERIMENT_NAME = 'ai-560-student-projects'\\n\",\n",
    "            \"STUDENT_NAME = 'Your Name'\\n\",\n",
    "            \"PROJECT_TITLE = 'Your Project Title'\\n\",\n",
    "            \"\\n\",\n",
    "            \"print(f'Configuration loaded for: {MODEL_NAME}')\\n\",\n",
    "            \"print(f'Student: {STUDENT_NAME}')\\n\",\n",
    "            \"print(f'Project: {PROJECT_TITLE}')\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Cell 3: Import libraries\n",
    "    notebook[\"cells\"].append({\n",
    "        \"cell_type\": \"code\",\n",
    "        \"metadata\": {},\n",
    "        \"execution_count\": None,\n",
    "        \"outputs\": [],\n",
    "        \"source\": [\n",
    "            \"import mlflow\\n\",\n",
    "            \"import mlflow.pyfunc\\n\",\n",
    "            \"from mlflow.models.signature import ModelSignature\\n\",\n",
    "            \"from mlflow.types.schema import Schema, ColSpec\\n\",\n",
    "            \"from mlflow.types import DataType\\n\",\n",
    "            \"import pandas as pd\\n\",\n",
    "            \"import torch\\n\",\n",
    "            \"from datetime import datetime\\n\",\n",
    "            \"import json\\n\",\n",
    "            \"from pathlib import Path\\n\",\n",
    "            \"\\n\",\n",
    "            \"print('Libraries imported successfully')\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Cell 4: Model wrapper class\n",
    "    notebook[\"cells\"].append({\n",
    "        \"cell_type\": \"code\",\n",
    "        \"metadata\": {},\n",
    "        \"execution_count\": None,\n",
    "        \"outputs\": [],\n",
    "        \"source\": [\n",
    "            \"class CustomModelWrapper(mlflow.pyfunc.PythonModel):\\n\",\n",
    "            \"    \\\"\\\"\\\"Wrapper class for MLflow model deployment\\\"\\\"\\\"\\n\",\n",
    "            \"    \\n\",\n",
    "            \"    def load_context(self, context):\\n\",\n",
    "            \"        \\\"\\\"\\\"Load model and dependencies\\\"\\\"\\\"\\n\",\n",
    "            \"        # Add your model loading code here\\n\",\n",
    "            \"        # Example: self.model = torch.load(context.artifacts['model_path'])\\n\",\n",
    "            \"        print('Model loaded successfully')\\n\",\n",
    "            \"    \\n\",\n",
    "            \"    def predict(self, context, model_input):\\n\",\n",
    "            \"        \\\"\\\"\\\"Run inference\\\"\\\"\\\"\\n\",\n",
    "            \"        # Add your prediction code here\\n\",\n",
    "            \"        # Example: return self.model(model_input)\\n\",\n",
    "            \"        return {'output': 'Model prediction would go here'}\\n\",\n",
    "            \"\\n\",\n",
    "            \"print('Model wrapper class defined')\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Cell 5: Define signature\n",
    "    notebook[\"cells\"].append({\n",
    "        \"cell_type\": \"code\",\n",
    "        \"metadata\": {},\n",
    "        \"execution_count\": None,\n",
    "        \"outputs\": [],\n",
    "        \"source\": [\n",
    "            \"# Define model signature\\n\",\n",
    "            \"input_schema = Schema([ColSpec(DataType.string, 'input')])\\n\",\n",
    "            \"output_schema = Schema([ColSpec(DataType.string, 'output')])\\n\",\n",
    "            \"signature = ModelSignature(inputs=input_schema, outputs=output_schema)\\n\",\n",
    "            \"\\n\",\n",
    "            \"# Create example input\\n\",\n",
    "            \"input_example = pd.DataFrame({'input': ['example input data']})\\n\",\n",
    "            \"\\n\",\n",
    "            \"print('Model signature defined')\\n\",\n",
    "            \"print(f'Input schema: {input_schema}')\\n\",\n",
    "            \"print(f'Output schema: {output_schema}')\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Cell 6: Register model\n",
    "    notebook[\"cells\"].append({\n",
    "        \"cell_type\": \"code\",\n",
    "        \"metadata\": {},\n",
    "        \"execution_count\": None,\n",
    "        \"outputs\": [],\n",
    "        \"source\": [\n",
    "            \"# Set MLflow tracking\\n\",\n",
    "            \"mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\\n\",\n",
    "            \"mlflow.set_experiment(EXPERIMENT_NAME)\\n\",\n",
    "            \"\\n\",\n",
    "            \"print(f'Registering model: {MODEL_NAME}')\\n\",\n",
    "            \"\\n\",\n",
    "            \"# Start MLflow run\\n\",\n",
    "            \"with mlflow.start_run(run_name=f\\\"{MODEL_NAME}-{datetime.now().strftime('%Y%m%d-%H%M%S')}\\\") as run:\\n\",\n",
    "            \"    # Log parameters\\n\",\n",
    "            \"    mlflow.log_param('model_version', MODEL_VERSION)\\n\",\n",
    "            \"    mlflow.log_param('student_name', STUDENT_NAME)\\n\",\n",
    "            \"    mlflow.log_param('project_title', PROJECT_TITLE)\\n\",\n",
    "            \"    \\n\",\n",
    "            \"    # Log model\\n\",\n",
    "            \"    mlflow.pyfunc.log_model(\\n\",\n",
    "            \"        artifact_path='model',\\n\",\n",
    "            \"        python_model=CustomModelWrapper(),\\n\",\n",
    "            \"        signature=signature,\\n\",\n",
    "            \"        input_example=input_example,\\n\",\n",
    "            \"        registered_model_name=MODEL_NAME\\n\",\n",
    "            \"    )\\n\",\n",
    "            \"    \\n\",\n",
    "            \"    print(f'‚úì Model registered: {MODEL_NAME}')\\n\",\n",
    "            \"    print(f'‚úì Run ID: {run.info.run_id}')\\n\",\n",
    "            \"    print(f'‚úì Check HP AI Studio Deployments tab')\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Cell 7: Verification\n",
    "    notebook[\"cells\"].append({\n",
    "        \"cell_type\": \"code\",\n",
    "        \"metadata\": {},\n",
    "        \"execution_count\": None,\n",
    "        \"outputs\": [],\n",
    "        \"source\": [\n",
    "            \"# Verify registration\\n\",\n",
    "            \"client = mlflow.tracking.MlflowClient()\\n\",\n",
    "            \"model_versions = client.search_model_versions(f\\\"name='{MODEL_NAME}'\\\")\\n\",\n",
    "            \"\\n\",\n",
    "            \"print(f'Model: {MODEL_NAME}')\\n\",\n",
    "            \"print(f'Versions registered: {len(model_versions)}')\\n\",\n",
    "            \"\\n\",\n",
    "            \"for mv in model_versions:\\n\",\n",
    "            \"    print(f\\\"\\\\nVersion: {mv.version}\\\")\\n\",\n",
    "            \"    print(f\\\"Stage: {mv.current_stage}\\\")\\n\",\n",
    "            \"    print(f\\\"Status: {mv.status}\\\")\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Save notebook\n",
    "    notebook_path = Path(\"Register_Model.ipynb\")\n",
    "    with open(notebook_path, 'w') as f:\n",
    "        json.dump(notebook, f, indent=2)\n",
    "    \n",
    "    return notebook_path\n",
    "\n",
    "# Create the notebook\n",
    "try:\n",
    "    notebook_path = create_register_notebook()\n",
    "    print(f\"‚úì Created: {notebook_path}\")\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"1. Open Register_Model.ipynb\")\n",
    "    print(\"2. Update configuration with your model details\")\n",
    "    print(\"3. Run all cells to register your model\")\n",
    "    print(\"4. Check HP AI Studio Deployments tab\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating notebook: {e}\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f2a60c9-4ea5-4721-aa2b-aa450163f979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "HUGGING FACE AUTHENTICATION\n",
      "============================================================\n",
      "\n",
      "Why authenticate with Hugging Face?\n",
      "  ‚Ä¢ Access to 500,000+ pre-trained models\n",
      "  ‚Ä¢ Download datasets for training\n",
      "  ‚Ä¢ Use gated models (Llama, Stable Diffusion, etc.)\n",
      "  ‚Ä¢ Share your trained models (optional)\n",
      "\n",
      "‚úì Already logged in as: Riya119\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Continue with this account? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Using existing authentication\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"HUGGING FACE AUTHENTICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def authenticate_huggingface():\n",
    "    \"\"\"Interactive Hugging Face authentication\"\"\"\n",
    "    \n",
    "    print(\"\\nWhy authenticate with Hugging Face?\")\n",
    "    print(\"  ‚Ä¢ Access to 500,000+ pre-trained models\")\n",
    "    print(\"  ‚Ä¢ Download datasets for training\")\n",
    "    print(\"  ‚Ä¢ Use gated models (Llama, Stable Diffusion, etc.)\")\n",
    "    print(\"  ‚Ä¢ Share your trained models (optional)\")\n",
    "    \n",
    "    # Check if already authenticated\n",
    "    try:\n",
    "        from huggingface_hub import whoami\n",
    "        user_info = whoami()\n",
    "        print(f\"\\n‚úì Already logged in as: {user_info['name']}\")\n",
    "        response = input(\"\\nContinue with this account? (y/n): \").lower()\n",
    "        if response == 'y':\n",
    "            print(\"‚úì Using existing authentication\")\n",
    "            return True\n",
    "    except:\n",
    "        print(\"\\n‚Ä¢ No existing Hugging Face login found\")\n",
    "    \n",
    "    # Get authentication token\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"HOW TO GET YOUR HUGGING FACE TOKEN:\")\n",
    "    print(\"-\"*60)\n",
    "    print(\"1. Go to: https://huggingface.co/settings/tokens\")\n",
    "    print(\"2. Click 'Create new token'\")\n",
    "    print(\"3. Name it: 'HP-AI-Studio-Student'\")\n",
    "    print(\"4. Select: 'Read' access (or 'Write' if you'll publish models)\")\n",
    "    print(\"5. Click 'Create token'\")\n",
    "    print(\"6. Copy the token (it looks like: hf_xxxxxxxxxxxxxxxxxxxxx)\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    choice = input(\"\\nDo you want to authenticate now? (y/n): \").lower()\n",
    "    \n",
    "    if choice == 'y':\n",
    "        try:\n",
    "            # Import login function\n",
    "            from huggingface_hub import login\n",
    "            \n",
    "            # Get token from user\n",
    "            token = input(\"\\nPaste your Hugging Face token here: \").strip()\n",
    "            \n",
    "            # Validate token format\n",
    "            if not token.startswith('hf_'):\n",
    "                print(\"\\n‚ö†Ô∏è Warning: Token should start with 'hf_'\")\n",
    "                confirm = input(\"Continue anyway? (y/n): \").lower()\n",
    "                if confirm != 'y':\n",
    "                    print(\"Authentication cancelled\")\n",
    "                    return False\n",
    "            \n",
    "            # Attempt login\n",
    "            print(\"\\nAuthenticating...\")\n",
    "            login(token=token, add_to_git_credential=True)\n",
    "            \n",
    "            # Verify authentication\n",
    "            from huggingface_hub import whoami\n",
    "            user_info = whoami()\n",
    "            \n",
    "            print(f\"\\n‚úì Successfully authenticated as: {user_info['name']}\")\n",
    "            print(\"‚úì You can now access Hugging Face models and datasets\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Authentication failed: {e}\")\n",
    "            print(\"\\nTroubleshooting:\")\n",
    "            print(\"  1. Verify token is correct\")\n",
    "            print(\"  2. Check token has required permissions\")\n",
    "            print(\"  3. Try creating a new token\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"\\n‚ÑπÔ∏è Skipping authentication\")\n",
    "        print(\"You can authenticate later by running:\")\n",
    "        print(\"  from huggingface_hub import login\")\n",
    "        print(\"  login()\")\n",
    "        return False\n",
    "\n",
    "# Run authentication\n",
    "hf_authenticated = authenticate_huggingface()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bf5151d-fe33-4593-8c22-c6d321d31965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üéâ SETUP COMPLETE!\n",
      "============================================================\n",
      "\n",
      "Your HP AI Studio environment is configured and ready.\n",
      "All core dependencies are installed and tested.\n",
      "\n",
      "‚ÑπÔ∏è GPU: Not detected (using CPU mode)\n",
      "‚úì Hugging Face: Authenticated\n",
      "\n",
      "============================================================\n",
      "NEXT STEPS FOR YOUR AI PROJECT:\n",
      "============================================================\n",
      "\n",
      "1. DEVELOP YOUR MODEL\n",
      "   - Load datasets using Hugging Face datasets library\n",
      "   - Fine-tune models or train from scratch\n",
      "   - Test and evaluate your model performance\n",
      "\n",
      "2. SAVE YOUR MODEL\n",
      "   - Use torch.save() for PyTorch models\n",
      "   - Save tokenizers and configurations\n",
      "   - Document model architecture and parameters\n",
      "\n",
      "3. REGISTER FOR DEPLOYMENT\n",
      "   - Open Register_Model.ipynb\n",
      "   - Update configuration with your model details\n",
      "   - Run all cells to register with MLflow\n",
      "   - Check HP AI Studio Deployments tab\n",
      "\n",
      "4. CREATE YOUR INTERFACE\n",
      "   - Use Gradio for interactive UIs\n",
      "   - Build REST APIs with FastAPI\n",
      "   - Integrate with existing applications\n",
      "\n",
      "5. DOCUMENT YOUR WORK\n",
      "   - Keep a development journal\n",
      "   - Screenshot important results\n",
      "   - Record process and iterations\n",
      "   - Prepare portfolio presentation\n",
      "\n",
      "============================================================\n",
      "HELPFUL RESOURCES:\n",
      "============================================================\n",
      "  ‚Ä¢ HP AI Studio Docs: https://zdocs.datascience.hp.com/docs/aistudio/\n",
      "  ‚Ä¢ Hugging Face: https://huggingface.co/\n",
      "  ‚Ä¢ MLflow Documentation: https://mlflow.org/docs/latest/\n",
      "  ‚Ä¢ PyTorch Tutorials: https://pytorch.org/tutorials/\n",
      "  ‚Ä¢ Gradio Documentation: https://gradio.app/docs/\n",
      "\n",
      "============================================================\n",
      "REMEMBER:\n",
      "============================================================\n",
      "  ‚Ä¢ Save your work frequently (Ctrl+S)\n",
      "  ‚Ä¢ Document your process in your project journal\n",
      "  ‚Ä¢ Test on small datasets before full training\n",
      "  ‚Ä¢ Ask for help in office hours if needed\n",
      "  ‚Ä¢ Clear GPU memory: torch.cuda.empty_cache()\n",
      "\n",
      "‚úì You're ready to begin your AI project!\n",
      "  Good luck with your creative AI development!\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ SETUP COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nYour HP AI Studio environment is configured and ready.\")\n",
    "print(\"All core dependencies are installed and tested.\")\n",
    "\n",
    "if gpu_available:\n",
    "    print(\"\\n‚úì GPU: Detected and functional\")\n",
    "else:\n",
    "    print(\"\\n‚ÑπÔ∏è GPU: Not detected (using CPU mode)\")\n",
    "\n",
    "if hf_authenticated:\n",
    "    print(\"‚úì Hugging Face: Authenticated\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Hugging Face: Not authenticated (optional)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NEXT STEPS FOR YOUR AI PROJECT:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. DEVELOP YOUR MODEL\")\n",
    "print(\"   - Load datasets using Hugging Face datasets library\")\n",
    "print(\"   - Fine-tune models or train from scratch\")\n",
    "print(\"   - Test and evaluate your model performance\")\n",
    "\n",
    "print(\"\\n2. SAVE YOUR MODEL\")\n",
    "print(\"   - Use torch.save() for PyTorch models\")\n",
    "print(\"   - Save tokenizers and configurations\")\n",
    "print(\"   - Document model architecture and parameters\")\n",
    "\n",
    "print(\"\\n3. REGISTER FOR DEPLOYMENT\")\n",
    "print(\"   - Open Register_Model.ipynb\")\n",
    "print(\"   - Update configuration with your model details\")\n",
    "print(\"   - Run all cells to register with MLflow\")\n",
    "print(\"   - Check HP AI Studio Deployments tab\")\n",
    "\n",
    "print(\"\\n4. CREATE YOUR INTERFACE\")\n",
    "print(\"   - Use Gradio for interactive UIs\")\n",
    "print(\"   - Build REST APIs with FastAPI\")\n",
    "print(\"   - Integrate with existing applications\")\n",
    "\n",
    "print(\"\\n5. DOCUMENT YOUR WORK\")\n",
    "print(\"   - Keep a development journal\")\n",
    "print(\"   - Screenshot important results\")\n",
    "print(\"   - Record process and iterations\")\n",
    "print(\"   - Prepare portfolio presentation\")\n",
    "\n",
    "if not hf_authenticated:\n",
    "    print(\"\\n‚ö†Ô∏è RECOMMENDATION:\")\n",
    "    print(\"   Run Cell 7 again to set up Hugging Face authentication\")\n",
    "    print(\"   This will give you access to more models and datasets\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"HELPFUL RESOURCES:\")\n",
    "print(\"=\"*60)\n",
    "print(\"  ‚Ä¢ HP AI Studio Docs: https://zdocs.datascience.hp.com/docs/aistudio/\")\n",
    "print(\"  ‚Ä¢ Hugging Face: https://huggingface.co/\")\n",
    "print(\"  ‚Ä¢ MLflow Documentation: https://mlflow.org/docs/latest/\")\n",
    "print(\"  ‚Ä¢ PyTorch Tutorials: https://pytorch.org/tutorials/\")\n",
    "print(\"  ‚Ä¢ Gradio Documentation: https://gradio.app/docs/\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"REMEMBER:\")\n",
    "print(\"=\"*60)\n",
    "print(\"  ‚Ä¢ Save your work frequently (Ctrl+S)\")\n",
    "print(\"  ‚Ä¢ Document your process in your project journal\")\n",
    "print(\"  ‚Ä¢ Test on small datasets before full training\")\n",
    "print(\"  ‚Ä¢ Ask for help in office hours if needed\")\n",
    "print(\"  ‚Ä¢ Clear GPU memory: torch.cuda.empty_cache()\")\n",
    "\n",
    "print(\"\\n‚úì You're ready to begin your AI project!\")\n",
    "print(\"  Good luck with your creative AI development!\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38510d87-3557-4279-88eb-1ad092ffff87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /opt/conda/lib/python3.12/site-packages (3.0.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.12/site-packages (1.7.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (4.50.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (4.67.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (2.10.0.dev20251110+cu128)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (1.16.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (1.1.2)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (0.27.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: shellingham in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (78.1.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1.3)\n",
      "Requirement already satisfied: pytorch-triton==3.5.1+gitbfeb0668 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.5.1+gitbfeb0668)\n",
      "Collecting huggingface-hub>=0.15.1 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.34.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.34.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.34.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.7.4)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.15.1->sentence-transformers) (1.0.9)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.15.1->sentence-transformers) (1.3.1)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.15.1->sentence-transformers) (0.16.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.12/site-packages (from typer-slim->huggingface-hub>=0.15.1->sentence-transformers) (8.2.1)\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: huggingface-hub\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface_hub 1.1.2\n",
      "    Uninstalling huggingface_hub-1.1.2:\n",
      "      Successfully uninstalled huggingface_hub-1.1.2\n",
      "Successfully installed huggingface-hub-0.36.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99a1d932-1f02-4ccf-9caf-c7d74fe0a4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Initializing PRISM Brain V3...\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# PRISM BRAIN V3 - FIXED ANALYSIS ENGINE\n",
    "# =====================================================\n",
    "\n",
    "import json\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "import requests\n",
    "\n",
    "# For embeddings and clustering\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "print(\"üß† Initializing PRISM Brain V3...\")\n",
    "\n",
    "class PRISMBrainV3:\n",
    "    \"\"\"Enhanced analysis with proper classification and theme detection\"\"\"\n",
    "    \n",
    "    def __init__(self, training_data, figjam_token):\n",
    "        self.projects = {}\n",
    "        self.figjam_token = figjam_token\n",
    "        \n",
    "        # Load training data for pattern learning\n",
    "        print(\"üìö Loading training data...\")\n",
    "        self.training_data = training_data\n",
    "        self._learn_patterns()\n",
    "        \n",
    "        # Initialize embeddings model for semantic analysis\n",
    "        print(\"ü§ñ Loading embedding model...\")\n",
    "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        \n",
    "        print(\"‚úÖ PRISM Brain V3 ready!\")\n",
    "    \n",
    "    def _learn_patterns(self):\n",
    "        \"\"\"Learn content type patterns from training data\"\"\"\n",
    "        self.type_keywords = defaultdict(list)\n",
    "        self.type_patterns = {}\n",
    "        \n",
    "        # Extract keywords per content type from training data\n",
    "        for board in self.training_data[:100]:  # Sample for speed\n",
    "            for note in board['notes']:\n",
    "                content_type = note['content_type']\n",
    "                text = note['text'].lower()\n",
    "                \n",
    "                # Extract significant words\n",
    "                words = [w for w in re.findall(r'\\b\\w+\\b', text) if len(w) > 3]\n",
    "                self.type_keywords[content_type].extend(words)\n",
    "        \n",
    "        # Get most common keywords per type\n",
    "        for content_type, words in self.type_keywords.items():\n",
    "            common = Counter(words).most_common(20)\n",
    "            self.type_patterns[content_type] = [w for w, _ in common]\n",
    "    \n",
    "    def create_project(self, name):\n",
    "        \"\"\"Create new project\"\"\"\n",
    "        project_id = hashlib.md5(name.encode()).hexdigest()[:12]\n",
    "        self.projects[project_id] = {\n",
    "            'name': name,\n",
    "            'created': datetime.now(),\n",
    "            'notes': [],\n",
    "            'sources': []\n",
    "        }\n",
    "        return project_id\n",
    "    \n",
    "    def ingest_figjam_url(self, project_id, url):\n",
    "        \"\"\"Ingest FigJam board from URL\"\"\"\n",
    "        try:\n",
    "            # Extract file key from URL\n",
    "            file_key = url.split('/board/')[1].split('?')[0].split('/')[0]\n",
    "            \n",
    "            # Fetch from FigJam API\n",
    "            headers = {'X-Figma-Token': self.figjam_token}\n",
    "            response = requests.get(\n",
    "                f'https://api.figma.com/v1/files/{file_key}',\n",
    "                headers=headers,\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                return {'error': f'API error: {response.status_code}'}\n",
    "            \n",
    "            data = response.json()\n",
    "            notes_processed = self._extract_figjam_notes(project_id, data, url)\n",
    "            \n",
    "            return {\n",
    "                'notes': notes_processed,\n",
    "                'connections': 0,\n",
    "                'source_url': url\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {'error': str(e)}\n",
    "    \n",
    "    def _extract_figjam_notes(self, project_id, figjam_data, source_url):\n",
    "        \"\"\"Extract and classify notes from FigJam data\"\"\"\n",
    "        notes_count = 0\n",
    "        \n",
    "        def traverse_nodes(node, path=\"\"):\n",
    "            nonlocal notes_count\n",
    "            \n",
    "            # Check if this is a sticky note\n",
    "            if node.get('type') == 'STICKY':\n",
    "                text = node.get('characters', '').strip()\n",
    "                if not text:\n",
    "                    return\n",
    "                \n",
    "                # Extract metadata\n",
    "                author = node.get('authorName', 'Unknown')\n",
    "                color = self._normalize_figjam_color(node.get('backgroundColor', {}))\n",
    "                \n",
    "                # Classify the note\n",
    "                classification = self._classify_note(text, color)\n",
    "                \n",
    "                # Create note object\n",
    "                note = {\n",
    "                    'id': node.get('id', f'note_{notes_count}'),\n",
    "                    'text': text,\n",
    "                    'predicted_type': classification['type'],\n",
    "                    'confidence': classification['confidence'],\n",
    "                    'priority': classification['priority'],\n",
    "                    'color': color,\n",
    "                    'author': author,\n",
    "                    'source': source_url,\n",
    "                    'source_type': 'figjam',\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "                \n",
    "                self.projects[project_id]['notes'].append(note)\n",
    "                notes_count += 1\n",
    "            \n",
    "            # Recurse through children\n",
    "            for child in node.get('children', []):\n",
    "                traverse_nodes(child, f\"{path}/{node.get('name', 'node')}\")\n",
    "        \n",
    "        # Start traversal from document root\n",
    "        traverse_nodes(figjam_data.get('document', {}))\n",
    "        \n",
    "        # Add source\n",
    "        self.projects[project_id]['sources'].append({\n",
    "            'type': 'figjam',\n",
    "            'url': source_url,\n",
    "            'processed': datetime.now().isoformat()\n",
    "        })\n",
    "        \n",
    "        return notes_count\n",
    "    \n",
    "    def _normalize_figjam_color(self, bg_color):\n",
    "        \"\"\"Normalize FigJam color to standard types\"\"\"\n",
    "        if not bg_color:\n",
    "            return 'gray'\n",
    "        \n",
    "        r = bg_color.get('r', 0)\n",
    "        g = bg_color.get('g', 0)\n",
    "        b = bg_color.get('b', 0)\n",
    "        \n",
    "        # Convert to closest standard color\n",
    "        if r > 0.8 and g < 0.3 and b < 0.3:\n",
    "            return 'red'\n",
    "        elif r > 0.8 and g > 0.6 and b < 0.3:\n",
    "            return 'orange'\n",
    "        elif r > 0.8 and g > 0.8 and b < 0.3:\n",
    "            return 'yellow'\n",
    "        elif r < 0.3 and g > 0.6 and b < 0.3:\n",
    "            return 'green'\n",
    "        elif r < 0.4 and g < 0.4 and b > 0.7:\n",
    "            return 'blue'\n",
    "        elif r > 0.6 and g < 0.4 and b > 0.6:\n",
    "            return 'purple'\n",
    "        else:\n",
    "            return 'gray'\n",
    "    \n",
    "    def _classify_note(self, text, color):\n",
    "        \"\"\"Classify note content using enhanced logic\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        # Score each content type\n",
    "        scores = {}\n",
    "        \n",
    "        # PAIN_POINT indicators\n",
    "        pain_words = ['frustrated', 'difficult', 'problem', 'issue', 'struggle', \n",
    "                      'confusing', 'annoying', 'broken', 'error', 'fail', 'hard to']\n",
    "        scores['pain_point'] = sum(1 for w in pain_words if w in text_lower)\n",
    "        \n",
    "        # QUESTION indicators\n",
    "        question_words = ['how', 'what', 'why', 'when', 'where', 'who', 'which', 'could', 'would', 'should']\n",
    "        scores['question'] = sum(1 for w in question_words if w in text_lower)\n",
    "        if '?' in text:\n",
    "            scores['question'] += 2\n",
    "        \n",
    "        # IDEA indicators\n",
    "        idea_words = ['could', 'should', 'what if', 'maybe', 'propose', 'suggest', \n",
    "                      'idea:', 'consider', 'alternative', 'potential']\n",
    "        scores['idea'] = sum(1 for w in idea_words if w in text_lower)\n",
    "        \n",
    "        # QUOTE indicators\n",
    "        if '\"' in text or \"'\" in text or text.startswith('\"') or 'said' in text_lower:\n",
    "            scores['quote'] = 3\n",
    "        else:\n",
    "            scores['quote'] = 0\n",
    "        \n",
    "        # POSITIVE indicators\n",
    "        positive_words = ['love', 'great', 'excellent', 'perfect', 'amazing', \n",
    "                         'wonderful', 'helpful', 'easy', 'intuitive', 'works well']\n",
    "        scores['positive'] = sum(1 for w in positive_words if w in text_lower)\n",
    "        \n",
    "        # Get highest scoring type\n",
    "        if max(scores.values()) > 0:\n",
    "            predicted_type = max(scores, key=scores.get)\n",
    "            confidence = min(0.95, scores[predicted_type] / 5.0)\n",
    "        else:\n",
    "            predicted_type = 'neutral'\n",
    "            confidence = 0.5\n",
    "        \n",
    "        # Determine priority\n",
    "        if predicted_type == 'pain_point' or scores.get('pain_point', 0) >= 2:\n",
    "            priority = 'high'\n",
    "        elif predicted_type in ['question', 'idea']:\n",
    "            priority = 'medium'\n",
    "        else:\n",
    "            priority = 'low'\n",
    "        \n",
    "        return {\n",
    "            'type': predicted_type,\n",
    "            'confidence': confidence,\n",
    "            'priority': priority,\n",
    "            'scores': scores\n",
    "        }\n",
    "    \n",
    "    def ingest_audio_file(self, project_id, file_path):\n",
    "        \"\"\"Process audio file with Whisper\"\"\"\n",
    "        try:\n",
    "            import whisper\n",
    "            model = whisper.load_model(\"base\")\n",
    "            result = model.transcribe(file_path)\n",
    "            \n",
    "            # Process segments as notes\n",
    "            for i, segment in enumerate(result['segments']):\n",
    "                text = segment['text'].strip()\n",
    "                classification = self._classify_note(text, 'none')\n",
    "                \n",
    "                note = {\n",
    "                    'id': f'audio_{i}',\n",
    "                    'text': text,\n",
    "                    'predicted_type': classification['type'],\n",
    "                    'confidence': classification['confidence'],\n",
    "                    'priority': classification['priority'],\n",
    "                    'author': 'Audio Transcript',\n",
    "                    'source': file_path,\n",
    "                    'source_type': 'audio',\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "                \n",
    "                self.projects[project_id]['notes'].append(note)\n",
    "            \n",
    "            self.projects[project_id]['sources'].append({\n",
    "                'type': 'audio',\n",
    "                'file': file_path,\n",
    "                'processed': datetime.now().isoformat()\n",
    "            })\n",
    "            \n",
    "            return {'notes': len(result['segments'])}\n",
    "        except Exception as e:\n",
    "            return {'error': str(e)}\n",
    "    \n",
    "    def ingest_document_file(self, project_id, file_path):\n",
    "        \"\"\"Process document file\"\"\"\n",
    "        try:\n",
    "            if file_path.endswith('.pdf'):\n",
    "                import PyPDF2\n",
    "                with open(file_path, 'rb') as f:\n",
    "                    reader = PyPDF2.PdfReader(f)\n",
    "                    text = \"\"\n",
    "                    for page in reader.pages:\n",
    "                        text += page.extract_text()\n",
    "            elif file_path.endswith('.txt'):\n",
    "                with open(file_path, 'r') as f:\n",
    "                    text = f.read()\n",
    "            else:\n",
    "                return {'error': 'Unsupported format'}\n",
    "            \n",
    "            # Split into paragraphs\n",
    "            paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
    "            \n",
    "            for i, para in enumerate(paragraphs):\n",
    "                classification = self._classify_note(para, 'none')\n",
    "                \n",
    "                note = {\n",
    "                    'id': f'doc_{i}',\n",
    "                    'text': para,\n",
    "                    'predicted_type': classification['type'],\n",
    "                    'confidence': classification['confidence'],\n",
    "                    'priority': classification['priority'],\n",
    "                    'author': 'Document',\n",
    "                    'source': file_path,\n",
    "                    'source_type': 'document',\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "                \n",
    "                self.projects[project_id]['notes'].append(note)\n",
    "            \n",
    "            self.projects[project_id]['sources'].append({\n",
    "                'type': 'document',\n",
    "                'file': file_path,\n",
    "                'processed': datetime.now().isoformat()\n",
    "            })\n",
    "            \n",
    "            return {'notes': len(paragraphs)}\n",
    "        except Exception as e:\n",
    "            return {'error': str(e)}\n",
    "    \n",
    "    def synthesize_project(self, project_id):\n",
    "        \"\"\"Generate comprehensive analysis with ENHANCED theme detection\"\"\"\n",
    "        if project_id not in self.projects:\n",
    "            return {'error': 'Project not found'}\n",
    "        \n",
    "        project = self.projects[project_id]\n",
    "        notes = project['notes']\n",
    "        \n",
    "        if not notes:\n",
    "            return {'error': 'No notes to analyze'}\n",
    "        \n",
    "        # Basic stats\n",
    "        total_notes = len(notes)\n",
    "        contributors = set(n['author'] for n in notes)\n",
    "        \n",
    "        # Content distribution\n",
    "        by_type = defaultdict(list)\n",
    "        for note in notes:\n",
    "            by_type[note['predicted_type']].append(note)\n",
    "        \n",
    "        # Priority distribution\n",
    "        by_priority = defaultdict(list)\n",
    "        for note in notes:\n",
    "            by_priority[note['priority']].append(note)\n",
    "        \n",
    "        # ENHANCED THEME DETECTION using embeddings and clustering\n",
    "        themes = self._detect_themes(notes)\n",
    "        \n",
    "        # High priority action items (deduplicated)\n",
    "        high_priority = by_priority.get('high', [])\n",
    "        action_items = []\n",
    "        seen_texts = set()\n",
    "        \n",
    "        for note in high_priority[:15]:  # Limit to top 15\n",
    "            text_key = note['text'][:50].lower()\n",
    "            if text_key not in seen_texts:\n",
    "                action_items.append({\n",
    "                    'type': note['predicted_type'],\n",
    "                    'text': note['text'],\n",
    "                    'confidence': note['confidence'],\n",
    "                    'author': note['author']\n",
    "                })\n",
    "                seen_texts.add(text_key)\n",
    "        \n",
    "        # Calculate average confidence\n",
    "        avg_confidence = np.mean([n['confidence'] for n in notes])\n",
    "        \n",
    "        return {\n",
    "            'project_name': project['name'],\n",
    "            'generated': datetime.now().isoformat(),\n",
    "            'total_notes': total_notes,\n",
    "            'total_sources': len(project['sources']),\n",
    "            'contributors': len(contributors),\n",
    "            'avg_confidence': avg_confidence,\n",
    "            'by_type': {t: len(notes) for t, notes in by_type.items()},\n",
    "            'by_priority': {p: len(notes) for p, notes in by_priority.items()},\n",
    "            'themes': themes,\n",
    "            'action_items': action_items\n",
    "        }\n",
    "    \n",
    "    def _detect_themes(self, notes, min_cluster_size=3):\n",
    "        \"\"\"Detect themes using TF-IDF and clustering\"\"\"\n",
    "        if len(notes) < min_cluster_size:\n",
    "            return []\n",
    "        \n",
    "        # Extract texts\n",
    "        texts = [n['text'] for n in notes]\n",
    "        \n",
    "        # Use TF-IDF for theme extraction\n",
    "        try:\n",
    "            vectorizer = TfidfVectorizer(\n",
    "                max_features=100,\n",
    "                stop_words='english',\n",
    "                ngram_range=(1, 2),\n",
    "                min_df=2\n",
    "            )\n",
    "            \n",
    "            tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "            feature_names = vectorizer.get_feature_names_out()\n",
    "            \n",
    "            # Get embeddings for clustering\n",
    "            embeddings = self.embedding_model.encode(texts)\n",
    "            \n",
    "            # Cluster similar notes\n",
    "            clustering = DBSCAN(eps=0.5, min_samples=min_cluster_size).fit(embeddings)\n",
    "            \n",
    "            # Extract themes from clusters\n",
    "            themes = []\n",
    "            for cluster_id in set(clustering.labels_):\n",
    "                if cluster_id == -1:  # Skip noise\n",
    "                    continue\n",
    "                \n",
    "                # Get notes in this cluster\n",
    "                cluster_indices = [i for i, label in enumerate(clustering.labels_) if label == cluster_id]\n",
    "                cluster_texts = [texts[i] for i in cluster_indices]\n",
    "                \n",
    "                # Find top terms for this cluster\n",
    "                cluster_tfidf = vectorizer.transform(cluster_texts)\n",
    "                scores = np.asarray(cluster_tfidf.sum(axis=0)).flatten()\n",
    "                top_indices = scores.argsort()[-3:][::-1]\n",
    "                theme_terms = [feature_names[i] for i in top_indices]\n",
    "                \n",
    "                themes.append({\n",
    "                    'name': ' + '.join(theme_terms).title(),\n",
    "                    'frequency': len(cluster_indices),\n",
    "                    'example': cluster_texts[0][:100]\n",
    "                })\n",
    "            \n",
    "            # Sort by frequency\n",
    "            themes.sort(key=lambda x: x['frequency'], reverse=True)\n",
    "            return themes[:5]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Theme detection error: {e}\")\n",
    "            # Fallback: simple keyword frequency\n",
    "            all_text = ' '.join(texts).lower()\n",
    "            words = re.findall(r'\\b\\w{4,}\\b', all_text)\n",
    "            common = Counter(words).most_common(5)\n",
    "            return [{'name': word.title(), 'frequency': count} for word, count in common]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f3c2c11-3eaa-430d-8ce8-eaff9c191059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Initializing PRISM Brain V3...\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# PRISM BRAIN V3 - FIXED ANALYSIS ENGINE\n",
    "# =====================================================\n",
    "\n",
    "import json\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "import requests\n",
    "\n",
    "# For embeddings and clustering\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "print(\"üß† Initializing PRISM Brain V3...\")\n",
    "\n",
    "class PRISMBrainV3:\n",
    "    \"\"\"Enhanced analysis with proper classification and theme detection\"\"\"\n",
    "    \n",
    "    def __init__(self, training_data, figjam_token):\n",
    "        self.projects = {}\n",
    "        self.figjam_token = figjam_token\n",
    "        \n",
    "        # Load training data for pattern learning\n",
    "        print(\"üìö Loading training data...\")\n",
    "        self.training_data = training_data\n",
    "        self._learn_patterns()\n",
    "        \n",
    "        # Initialize embeddings model for semantic analysis\n",
    "        print(\"ü§ñ Loading embedding model...\")\n",
    "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        \n",
    "        print(\"‚úÖ PRISM Brain V3 ready!\")\n",
    "    \n",
    "    def _learn_patterns(self):\n",
    "        \"\"\"Learn content type patterns from training data\"\"\"\n",
    "        self.type_keywords = defaultdict(list)\n",
    "        self.type_patterns = {}\n",
    "        \n",
    "        # Extract keywords per content type from training data\n",
    "        for board in self.training_data[:100]:  # Sample for speed\n",
    "            for note in board['notes']:\n",
    "                # Handle different data structures\n",
    "                content_type = note.get('content_type') or note.get('type', 'neutral')\n",
    "                text = note.get('text', '').lower()\n",
    "                \n",
    "                if not text:\n",
    "                    continue\n",
    "                \n",
    "                # Extract significant words\n",
    "                words = [w for w in re.findall(r'\\b\\w+\\b', text) if len(w) > 3]\n",
    "                self.type_keywords[content_type].extend(words)\n",
    "        \n",
    "        # Get most common keywords per type\n",
    "        for content_type, words in self.type_keywords.items():\n",
    "            common = Counter(words).most_common(20)\n",
    "            self.type_patterns[content_type] = [w for w, _ in common]\n",
    "    \n",
    "    def create_project(self, name):\n",
    "        \"\"\"Create new project\"\"\"\n",
    "        project_id = hashlib.md5(name.encode()).hexdigest()[:12]\n",
    "        self.projects[project_id] = {\n",
    "            'name': name,\n",
    "            'created': datetime.now(),\n",
    "            'notes': [],\n",
    "            'sources': []\n",
    "        }\n",
    "        return project_id\n",
    "    \n",
    "    def ingest_figjam_url(self, project_id, url):\n",
    "        \"\"\"Ingest FigJam board from URL\"\"\"\n",
    "        try:\n",
    "            # Extract file key from URL\n",
    "            file_key = url.split('/board/')[1].split('?')[0].split('/')[0]\n",
    "            \n",
    "            # Fetch from FigJam API\n",
    "            headers = {'X-Figma-Token': self.figjam_token}\n",
    "            response = requests.get(\n",
    "                f'https://api.figma.com/v1/files/{file_key}',\n",
    "                headers=headers,\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                return {'error': f'API error: {response.status_code}'}\n",
    "            \n",
    "            data = response.json()\n",
    "            notes_processed = self._extract_figjam_notes(project_id, data, url)\n",
    "            \n",
    "            return {\n",
    "                'notes': notes_processed,\n",
    "                'connections': 0,\n",
    "                'source_url': url\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {'error': str(e)}\n",
    "    \n",
    "    def _extract_figjam_notes(self, project_id, figjam_data, source_url):\n",
    "        \"\"\"Extract and classify notes from FigJam data\"\"\"\n",
    "        notes_count = 0\n",
    "        \n",
    "        def traverse_nodes(node, path=\"\"):\n",
    "            nonlocal notes_count\n",
    "            \n",
    "            # Check if this is a sticky note\n",
    "            if node.get('type') == 'STICKY':\n",
    "                text = node.get('characters', '').strip()\n",
    "                if not text:\n",
    "                    return\n",
    "                \n",
    "                # Extract metadata\n",
    "                author = node.get('authorName', 'Unknown')\n",
    "                color = self._normalize_figjam_color(node.get('backgroundColor', {}))\n",
    "                \n",
    "                # Classify the note\n",
    "                classification = self._classify_note(text, color)\n",
    "                \n",
    "                # Create note object\n",
    "                note = {\n",
    "                    'id': node.get('id', f'note_{notes_count}'),\n",
    "                    'text': text,\n",
    "                    'predicted_type': classification['type'],\n",
    "                    'confidence': classification['confidence'],\n",
    "                    'priority': classification['priority'],\n",
    "                    'color': color,\n",
    "                    'author': author,\n",
    "                    'source': source_url,\n",
    "                    'source_type': 'figjam',\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "                \n",
    "                self.projects[project_id]['notes'].append(note)\n",
    "                notes_count += 1\n",
    "            \n",
    "            # Recurse through children\n",
    "            for child in node.get('children', []):\n",
    "                traverse_nodes(child, f\"{path}/{node.get('name', 'node')}\")\n",
    "        \n",
    "        # Start traversal from document root\n",
    "        traverse_nodes(figjam_data.get('document', {}))\n",
    "        \n",
    "        # Add source\n",
    "        self.projects[project_id]['sources'].append({\n",
    "            'type': 'figjam',\n",
    "            'url': source_url,\n",
    "            'processed': datetime.now().isoformat()\n",
    "        })\n",
    "        \n",
    "        return notes_count\n",
    "    \n",
    "    def _normalize_figjam_color(self, bg_color):\n",
    "        \"\"\"Normalize FigJam color to standard types\"\"\"\n",
    "        if not bg_color:\n",
    "            return 'gray'\n",
    "        \n",
    "        r = bg_color.get('r', 0)\n",
    "        g = bg_color.get('g', 0)\n",
    "        b = bg_color.get('b', 0)\n",
    "        \n",
    "        # Convert to closest standard color\n",
    "        if r > 0.8 and g < 0.3 and b < 0.3:\n",
    "            return 'red'\n",
    "        elif r > 0.8 and g > 0.6 and b < 0.3:\n",
    "            return 'orange'\n",
    "        elif r > 0.8 and g > 0.8 and b < 0.3:\n",
    "            return 'yellow'\n",
    "        elif r < 0.3 and g > 0.6 and b < 0.3:\n",
    "            return 'green'\n",
    "        elif r < 0.4 and g < 0.4 and b > 0.7:\n",
    "            return 'blue'\n",
    "        elif r > 0.6 and g < 0.4 and b > 0.6:\n",
    "            return 'purple'\n",
    "        else:\n",
    "            return 'gray'\n",
    "    \n",
    "    def _classify_note(self, text, color):\n",
    "        \"\"\"Classify note content using enhanced logic\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        # Score each content type\n",
    "        scores = {}\n",
    "        \n",
    "        # PAIN_POINT indicators\n",
    "        pain_words = ['frustrated', 'difficult', 'problem', 'issue', 'struggle', \n",
    "                      'confusing', 'annoying', 'broken', 'error', 'fail', 'hard to']\n",
    "        scores['pain_point'] = sum(1 for w in pain_words if w in text_lower)\n",
    "        \n",
    "        # QUESTION indicators\n",
    "        question_words = ['how', 'what', 'why', 'when', 'where', 'who', 'which', 'could', 'would', 'should']\n",
    "        scores['question'] = sum(1 for w in question_words if w in text_lower)\n",
    "        if '?' in text:\n",
    "            scores['question'] += 2\n",
    "        \n",
    "        # IDEA indicators\n",
    "        idea_words = ['could', 'should', 'what if', 'maybe', 'propose', 'suggest', \n",
    "                      'idea:', 'consider', 'alternative', 'potential']\n",
    "        scores['idea'] = sum(1 for w in idea_words if w in text_lower)\n",
    "        \n",
    "        # QUOTE indicators\n",
    "        if '\"' in text or \"'\" in text or text.startswith('\"') or 'said' in text_lower:\n",
    "            scores['quote'] = 3\n",
    "        else:\n",
    "            scores['quote'] = 0\n",
    "        \n",
    "        # POSITIVE indicators\n",
    "        positive_words = ['love', 'great', 'excellent', 'perfect', 'amazing', \n",
    "                         'wonderful', 'helpful', 'easy', 'intuitive', 'works well']\n",
    "        scores['positive'] = sum(1 for w in positive_words if w in text_lower)\n",
    "        \n",
    "        # Get highest scoring type\n",
    "        if max(scores.values()) > 0:\n",
    "            predicted_type = max(scores, key=scores.get)\n",
    "            confidence = min(0.95, scores[predicted_type] / 5.0)\n",
    "        else:\n",
    "            predicted_type = 'neutral'\n",
    "            confidence = 0.5\n",
    "        \n",
    "        # Determine priority\n",
    "        if predicted_type == 'pain_point' or scores.get('pain_point', 0) >= 2:\n",
    "            priority = 'high'\n",
    "        elif predicted_type in ['question', 'idea']:\n",
    "            priority = 'medium'\n",
    "        else:\n",
    "            priority = 'low'\n",
    "        \n",
    "        return {\n",
    "            'type': predicted_type,\n",
    "            'confidence': confidence,\n",
    "            'priority': priority,\n",
    "            'scores': scores\n",
    "        }\n",
    "    \n",
    "    def ingest_audio_file(self, project_id, file_path):\n",
    "        \"\"\"Process audio file with Whisper\"\"\"\n",
    "        try:\n",
    "            import whisper\n",
    "            model = whisper.load_model(\"base\")\n",
    "            result = model.transcribe(file_path)\n",
    "            \n",
    "            # Process segments as notes\n",
    "            for i, segment in enumerate(result['segments']):\n",
    "                text = segment['text'].strip()\n",
    "                classification = self._classify_note(text, 'none')\n",
    "                \n",
    "                note = {\n",
    "                    'id': f'audio_{i}',\n",
    "                    'text': text,\n",
    "                    'predicted_type': classification['type'],\n",
    "                    'confidence': classification['confidence'],\n",
    "                    'priority': classification['priority'],\n",
    "                    'author': 'Audio Transcript',\n",
    "                    'source': file_path,\n",
    "                    'source_type': 'audio',\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "                \n",
    "                self.projects[project_id]['notes'].append(note)\n",
    "            \n",
    "            self.projects[project_id]['sources'].append({\n",
    "                'type': 'audio',\n",
    "                'file': file_path,\n",
    "                'processed': datetime.now().isoformat()\n",
    "            })\n",
    "            \n",
    "            return {'notes': len(result['segments'])}\n",
    "        except Exception as e:\n",
    "            return {'error': str(e)}\n",
    "    \n",
    "    def ingest_document_file(self, project_id, file_path):\n",
    "        \"\"\"Process document file\"\"\"\n",
    "        try:\n",
    "            if file_path.endswith('.pdf'):\n",
    "                import PyPDF2\n",
    "                with open(file_path, 'rb') as f:\n",
    "                    reader = PyPDF2.PdfReader(f)\n",
    "                    text = \"\"\n",
    "                    for page in reader.pages:\n",
    "                        text += page.extract_text()\n",
    "            elif file_path.endswith('.txt'):\n",
    "                with open(file_path, 'r') as f:\n",
    "                    text = f.read()\n",
    "            else:\n",
    "                return {'error': 'Unsupported format'}\n",
    "            \n",
    "            # Split into paragraphs\n",
    "            paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
    "            \n",
    "            for i, para in enumerate(paragraphs):\n",
    "                classification = self._classify_note(para, 'none')\n",
    "                \n",
    "                note = {\n",
    "                    'id': f'doc_{i}',\n",
    "                    'text': para,\n",
    "                    'predicted_type': classification['type'],\n",
    "                    'confidence': classification['confidence'],\n",
    "                    'priority': classification['priority'],\n",
    "                    'author': 'Document',\n",
    "                    'source': file_path,\n",
    "                    'source_type': 'document',\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "                \n",
    "                self.projects[project_id]['notes'].append(note)\n",
    "            \n",
    "            self.projects[project_id]['sources'].append({\n",
    "                'type': 'document',\n",
    "                'file': file_path,\n",
    "                'processed': datetime.now().isoformat()\n",
    "            })\n",
    "            \n",
    "            return {'notes': len(paragraphs)}\n",
    "        except Exception as e:\n",
    "            return {'error': str(e)}\n",
    "    \n",
    "    def synthesize_project(self, project_id):\n",
    "        \"\"\"Generate comprehensive analysis with ENHANCED theme detection\"\"\"\n",
    "        if project_id not in self.projects:\n",
    "            return {'error': 'Project not found'}\n",
    "        \n",
    "        project = self.projects[project_id]\n",
    "        notes = project['notes']\n",
    "        \n",
    "        if not notes:\n",
    "            return {'error': 'No notes to analyze'}\n",
    "        \n",
    "        # Basic stats\n",
    "        total_notes = len(notes)\n",
    "        contributors = set(n['author'] for n in notes)\n",
    "        \n",
    "        # Content distribution\n",
    "        by_type = defaultdict(list)\n",
    "        for note in notes:\n",
    "            by_type[note['predicted_type']].append(note)\n",
    "        \n",
    "        # Priority distribution\n",
    "        by_priority = defaultdict(list)\n",
    "        for note in notes:\n",
    "            by_priority[note['priority']].append(note)\n",
    "        \n",
    "        # ENHANCED THEME DETECTION using embeddings and clustering\n",
    "        themes = self._detect_themes(notes)\n",
    "        \n",
    "        # High priority action items (deduplicated)\n",
    "        high_priority = by_priority.get('high', [])\n",
    "        action_items = []\n",
    "        seen_texts = set()\n",
    "        \n",
    "        for note in high_priority[:15]:  # Limit to top 15\n",
    "            text_key = note['text'][:50].lower()\n",
    "            if text_key not in seen_texts:\n",
    "                action_items.append({\n",
    "                    'type': note['predicted_type'],\n",
    "                    'text': note['text'],\n",
    "                    'confidence': note['confidence'],\n",
    "                    'author': note['author']\n",
    "                })\n",
    "                seen_texts.add(text_key)\n",
    "        \n",
    "        # Calculate average confidence\n",
    "        avg_confidence = np.mean([n['confidence'] for n in notes])\n",
    "        \n",
    "        return {\n",
    "            'project_name': project['name'],\n",
    "            'generated': datetime.now().isoformat(),\n",
    "            'total_notes': total_notes,\n",
    "            'total_sources': len(project['sources']),\n",
    "            'contributors': len(contributors),\n",
    "            'avg_confidence': avg_confidence,\n",
    "            'by_type': {t: len(notes) for t, notes in by_type.items()},\n",
    "            'by_priority': {p: len(notes) for p, notes in by_priority.items()},\n",
    "            'themes': themes,\n",
    "            'action_items': action_items\n",
    "        }\n",
    "    \n",
    "    def _detect_themes(self, notes, min_cluster_size=3):\n",
    "        \"\"\"Detect themes using TF-IDF and clustering\"\"\"\n",
    "        if len(notes) < min_cluster_size:\n",
    "            return []\n",
    "        \n",
    "        # Extract texts\n",
    "        texts = [n['text'] for n in notes]\n",
    "        \n",
    "        # Use TF-IDF for theme extraction\n",
    "        try:\n",
    "            vectorizer = TfidfVectorizer(\n",
    "                max_features=100,\n",
    "                stop_words='english',\n",
    "                ngram_range=(1, 2),\n",
    "                min_df=2\n",
    "            )\n",
    "            \n",
    "            tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "            feature_names = vectorizer.get_feature_names_out()\n",
    "            \n",
    "            # Get embeddings for clustering\n",
    "            embeddings = self.embedding_model.encode(texts)\n",
    "            \n",
    "            # Cluster similar notes\n",
    "            clustering = DBSCAN(eps=0.5, min_samples=min_cluster_size).fit(embeddings)\n",
    "            \n",
    "            # Extract themes from clusters\n",
    "            themes = []\n",
    "            for cluster_id in set(clustering.labels_):\n",
    "                if cluster_id == -1:  # Skip noise\n",
    "                    continue\n",
    "                \n",
    "                # Get notes in this cluster\n",
    "                cluster_indices = [i for i, label in enumerate(clustering.labels_) if label == cluster_id]\n",
    "                cluster_texts = [texts[i] for i in cluster_indices]\n",
    "                \n",
    "                # Find top terms for this cluster\n",
    "                cluster_tfidf = vectorizer.transform(cluster_texts)\n",
    "                scores = np.asarray(cluster_tfidf.sum(axis=0)).flatten()\n",
    "                top_indices = scores.argsort()[-3:][::-1]\n",
    "                theme_terms = [feature_names[i] for i in top_indices]\n",
    "                \n",
    "                themes.append({\n",
    "                    'name': ' + '.join(theme_terms).title(),\n",
    "                    'frequency': len(cluster_indices),\n",
    "                    'example': cluster_texts[0][:100]\n",
    "                })\n",
    "            \n",
    "            # Sort by frequency\n",
    "            themes.sort(key=lambda x: x['frequency'], reverse=True)\n",
    "            return themes[:5]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Theme detection error: {e}\")\n",
    "            # Fallback: simple keyword frequency\n",
    "            all_text = ' '.join(texts).lower()\n",
    "            words = re.findall(r'\\b\\w{4,}\\b', all_text)\n",
    "            common = Counter(words).most_common(5)\n",
    "            return [{'name': word.title(), 'frequency': count} for word, count in common]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a8caf5e-8709-4c2b-ac29-efd016a361e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Loading training data...\n",
      "‚úÖ Loaded 10000 boards\n",
      "üìö Loading training data...\n",
      "ü§ñ Loading embedding model...\n",
      "‚úÖ PRISM Brain V3 ready!\n",
      "‚úÖ Brain V3 initialized!\n",
      "Brain type: <class '__main__.PRISMBrainV3'>\n",
      "Brain has 0 projects\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "import json\n",
    "\n",
    "print(\"üìö Loading training data...\")\n",
    "with open('/home/jovyan/local/DeepLearning/synthetic_data/full_10k/training_data.json', 'r') as f:\n",
    "    training_data = json.load(f)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(training_data)} boards\")\n",
    "\n",
    "# Your FigJam token\n",
    "figjam_token = \"figd_YP-yLbvxZ0jOVR9C54bCPveiHdkFB3uZD7hKQKDF\"\n",
    "\n",
    "# Create Brain V3 instance - passing empty list to skip pattern learning\n",
    "brain = PRISMBrainV3([], figjam_token)\n",
    "brain.training_data = training_data\n",
    "\n",
    "print(\"‚úÖ Brain V3 initialized!\")\n",
    "print(f\"Brain type: {type(brain)}\")\n",
    "print(f\"Brain has {len(brain.projects)} projects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "160d62ff-5e4f-44bb-848a-dd0ffb135584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé® Building PRISM UI V3...\n",
      "üì° Connecting to PRISM Brain V3...\n",
      "‚úÖ Connected to Brain V3\n",
      "üöÄ Launching PRISM V3...\n",
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://7d7c0fc217f4cd03ca.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://7d7c0fc217f4cd03ca.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =====================================================\n",
    "# GRADIO UI V3 - ENHANCED ANALYSIS OUTPUT\n",
    "# NOTE: Run the PRISM Brain V3 cell FIRST before this cell\n",
    "# =====================================================\n",
    "\n",
    "import gradio as gr\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üé® Building PRISM UI V3...\")\n",
    "\n",
    "# Reference to Brain V3 (must be initialized in a previous cell)\n",
    "# The brain variable should be available from the previous cell\n",
    "print(\"üì° Connecting to PRISM Brain V3...\")\n",
    "try:\n",
    "    # Test if brain exists by trying to access it\n",
    "    test = brain\n",
    "    print(\"‚úÖ Connected to Brain V3\")\n",
    "except NameError:\n",
    "    raise RuntimeError(\"‚ùå Brain V3 not found! Run the Brain V3 initialization cell first.\")\n",
    "\n",
    "\n",
    "current_project_id = None\n",
    "\n",
    "# =====================================================\n",
    "# UI FUNCTIONS\n",
    "# =====================================================\n",
    "\n",
    "def create_project(name):\n",
    "    global current_project_id\n",
    "    if not name:\n",
    "        return \"‚ùå Enter project name\"\n",
    "    current_project_id = brain.create_project(name)\n",
    "    return f\"‚úÖ Project created: {name}\\nüìã ID: {current_project_id}\"\n",
    "\n",
    "def upload_figjam(url):\n",
    "    global current_project_id\n",
    "    if not current_project_id:\n",
    "        return \"‚ùå Create project first\"\n",
    "    \n",
    "    result = brain.ingest_figjam_url(current_project_id, url)\n",
    "    if 'error' in result:\n",
    "        return f\"‚ùå {result['error']}\"\n",
    "    return f\"‚úÖ FigJam board analyzed!\\nüìä Notes processed: {result['notes']}\\nüîó Source: {result['source_url']}\"\n",
    "\n",
    "def upload_audio(file):\n",
    "    global current_project_id\n",
    "    if not current_project_id:\n",
    "        return \"‚ùå Create project first\"\n",
    "    if not file:\n",
    "        return \"‚ùå No file\"\n",
    "    \n",
    "    result = brain.ingest_audio_file(current_project_id, file.name)\n",
    "    if 'error' in result:\n",
    "        return f\"‚ùå {result['error']}\"\n",
    "    return f\"‚úÖ Audio transcribed!\\nüìä Segments analyzed: {result['notes']}\"\n",
    "\n",
    "def upload_doc(file):\n",
    "    global current_project_id\n",
    "    if not current_project_id:\n",
    "        return \"‚ùå Create project first\"\n",
    "    if not file:\n",
    "        return \"‚ùå No file\"\n",
    "    \n",
    "    result = brain.ingest_document_file(current_project_id, file.name)\n",
    "    if 'error' in result:\n",
    "        return f\"‚ùå {result['error']}\"\n",
    "    return f\"‚úÖ Document analyzed!\\nüìä Sections processed: {result['notes']}\"\n",
    "\n",
    "def analyze():\n",
    "    global current_project_id\n",
    "    if not current_project_id:\n",
    "        return \"‚ùå Create project first\"\n",
    "    \n",
    "    s = brain.synthesize_project(current_project_id)\n",
    "    \n",
    "    if 'error' in s:\n",
    "        return f\"‚ùå {s['error']}\"\n",
    "    \n",
    "    # Format enhanced report\n",
    "    output = f\"\"\"‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë                        PRISM ANALYSIS REPORT                                  ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "PROJECT          {s['project_name']}\n",
    "GENERATED        {s['generated']}\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "OVERVIEW\n",
    "  Total Notes           {s['total_notes']}\n",
    "  Data Sources          {s['total_sources']}\n",
    "  Contributors          {s['contributors']}\n",
    "  Avg Confidence        {s['avg_confidence']*100:.1f}%\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "CONTENT DISTRIBUTION\n",
    "\"\"\"\n",
    "    \n",
    "    # Sort by count and create bar chart\n",
    "    type_counts = sorted(s['by_type'].items(), key=lambda x: x[1], reverse=True)\n",
    "    max_count = max([c for _, c in type_counts]) if type_counts else 1\n",
    "    \n",
    "    for content_type, count in type_counts:\n",
    "        percentage = (count / s['total_notes']) * 100\n",
    "        bar_length = int((count / max_count) * 43)  # Max 43 chars for bar\n",
    "        bar = '‚ñà' * bar_length\n",
    "        output += f\"  {content_type.upper():20} {count:4}  {bar} {percentage:.1f}%\\n\"\n",
    "    \n",
    "    output += f\"\"\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "PRIORITY LEVELS\n",
    "\"\"\"\n",
    "    for priority in ['high', 'medium', 'low']:\n",
    "        count = s['by_priority'].get(priority, 0)\n",
    "        output += f\"  {priority.upper():15} {count}\\n\"\n",
    "    \n",
    "    output += f\"\"\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "TOP THEMES\n",
    "\"\"\"\n",
    "    if s['themes']:\n",
    "        for i, theme in enumerate(s['themes'], 1):\n",
    "            bar_length = min(int(theme['frequency'] / 3), 50)\n",
    "            bar = '‚ñì' * bar_length\n",
    "            output += f\"  {i}. {theme['name']:30} {theme['frequency']:3}  {bar}\\n\"\n",
    "    else:\n",
    "        output += \"  No themes detected (need more data)\\n\"\n",
    "    \n",
    "    output += f\"\"\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "HIGH PRIORITY ACTIONS\n",
    "\"\"\"\n",
    "    if s['action_items']:\n",
    "        for i, item in enumerate(s['action_items'][:8], 1):\n",
    "            # Truncate text to fit\n",
    "            text = item['text'][:75] + '...' if len(item['text']) > 75 else item['text']\n",
    "            output += f\"  {i}. [{item['type'].upper()}] {text}\\n\"\n",
    "            output += f\"      Confidence: {item['confidence']*100:.0f}% | {item['author']}\\n\"\n",
    "    else:\n",
    "        output += \"  No high priority items found\\n\"\n",
    "    \n",
    "    output += \"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\"\n",
    "    \n",
    "    return output\n",
    "\n",
    "# BUILD UI\n",
    "with gr.Blocks(title=\"PRISM V3\") as demo:\n",
    "    gr.Markdown(\"# PRISM V3 - Enhanced Research Synthesis\\n### Multi-Modal AI Analysis with Improved Classification\")\n",
    "    \n",
    "    gr.Markdown(\"## 1. Create Project\")\n",
    "    with gr.Row():\n",
    "        project_name = gr.Textbox(label=\"Project Name\", placeholder=\"Enter project name...\")\n",
    "        create_btn = gr.Button(\"Create\", variant=\"primary\")\n",
    "    create_status = gr.Textbox(label=\"Status\", lines=2)\n",
    "    \n",
    "    gr.Markdown(\"---\")\n",
    "    gr.Markdown(\"## 2. Upload Data Sources\")\n",
    "    \n",
    "    with gr.Tab(\"üìã FigJam Board\"):\n",
    "        figjam_url = gr.Textbox(\n",
    "            label=\"FigJam Board URL\",\n",
    "            placeholder=\"https://www.figma.com/board/...\"\n",
    "        )\n",
    "        figjam_btn = gr.Button(\"Analyze Board\", variant=\"primary\")\n",
    "        figjam_status = gr.Textbox(label=\"Status\", lines=3)\n",
    "    \n",
    "    with gr.Tab(\"üéôÔ∏è Audio File\"):\n",
    "        audio_file = gr.File(label=\"Audio (.mp3, .wav, .mov)\")\n",
    "        audio_btn = gr.Button(\"Process Audio\", variant=\"primary\")\n",
    "        audio_status = gr.Textbox(label=\"Status\", lines=3)\n",
    "    \n",
    "    with gr.Tab(\"üìÑ Document\"):\n",
    "        doc_file = gr.File(label=\"Document (.pdf, .txt)\")\n",
    "        doc_btn = gr.Button(\"Process Document\", variant=\"primary\")\n",
    "        doc_status = gr.Textbox(label=\"Status\", lines=3)\n",
    "    \n",
    "    gr.Markdown(\"---\")\n",
    "    gr.Markdown(\"## 3. Generate Analysis\")\n",
    "    \n",
    "    analyze_btn = gr.Button(\"üîç GENERATE SYNTHESIS REPORT\", variant=\"primary\", size=\"lg\")\n",
    "    \n",
    "    gr.Markdown(\"### Analysis Output\")\n",
    "    analysis_output = gr.Textbox(\n",
    "        label=\"Synthesis Report\",\n",
    "        lines=35,\n",
    "        show_copy_button=True,\n",
    "        elem_classes=[\"monospace\"]\n",
    "    )\n",
    "    \n",
    "    # Wire up events\n",
    "    create_btn.click(create_project, [project_name], [create_status])\n",
    "    figjam_btn.click(upload_figjam, [figjam_url], [figjam_status])\n",
    "    audio_btn.click(upload_audio, [audio_file], [audio_status])\n",
    "    doc_btn.click(upload_doc, [doc_file], [doc_status])\n",
    "    analyze_btn.click(analyze, [], [analysis_output])\n",
    "    \n",
    "    # Add custom CSS\n",
    "    demo.css = \"\"\"\n",
    "    .monospace textarea {\n",
    "        font-family: 'Courier New', monospace;\n",
    "        font-size: 12px;\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "print(\"üöÄ Launching PRISM V3...\")\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bae3b98-e0cd-4c65-8312-a706b8f03632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Initializing PRISM Brain V3...\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# PRISM BRAIN V3 - FIXED ANALYSIS ENGINE\n",
    "# =====================================================\n",
    "\n",
    "import json\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "import requests\n",
    "\n",
    "# For embeddings and clustering\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "print(\"üß† Initializing PRISM Brain V3...\")\n",
    "\n",
    "class PRISMBrainV3:\n",
    "    \"\"\"Enhanced analysis with proper classification and theme detection\"\"\"\n",
    "    \n",
    "    def __init__(self, training_data, figjam_token):\n",
    "        self.projects = {}\n",
    "        self.figjam_token = figjam_token\n",
    "        \n",
    "        # Load training data for pattern learning\n",
    "        print(\"üìö Loading training data...\")\n",
    "        self.training_data = training_data\n",
    "        self._learn_patterns()\n",
    "        \n",
    "        # Initialize embeddings model for semantic analysis\n",
    "        print(\"ü§ñ Loading embedding model...\")\n",
    "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        \n",
    "        print(\"‚úÖ PRISM Brain V3 ready!\")\n",
    "    \n",
    "    def _learn_patterns(self):\n",
    "        \"\"\"Learn content type patterns from training data\"\"\"\n",
    "        self.type_keywords = defaultdict(list)\n",
    "        self.type_patterns = {}\n",
    "        \n",
    "        # Extract keywords per content type from training data\n",
    "        for board in self.training_data[:100]:  # Sample for speed\n",
    "            for note in board['notes']:\n",
    "                # Handle different data structures\n",
    "                content_type = note.get('content_type') or note.get('type', 'neutral')\n",
    "                text = note.get('text', '').lower()\n",
    "                \n",
    "                if not text:\n",
    "                    continue\n",
    "                \n",
    "                # Extract significant words\n",
    "                words = [w for w in re.findall(r'\\b\\w+\\b', text) if len(w) > 3]\n",
    "                self.type_keywords[content_type].extend(words)\n",
    "        \n",
    "        # Get most common keywords per type\n",
    "        for content_type, words in self.type_keywords.items():\n",
    "            common = Counter(words).most_common(20)\n",
    "            self.type_patterns[content_type] = [w for w, _ in common]\n",
    "    \n",
    "    def create_project(self, name):\n",
    "        \"\"\"Create new project\"\"\"\n",
    "        project_id = hashlib.md5(name.encode()).hexdigest()[:12]\n",
    "        self.projects[project_id] = {\n",
    "            'name': name,\n",
    "            'created': datetime.now(),\n",
    "            'notes': [],\n",
    "            'sources': []\n",
    "        }\n",
    "        return project_id\n",
    "    \n",
    "    def ingest_figjam_url(self, project_id, url):\n",
    "        \"\"\"Ingest FigJam board from URL\"\"\"\n",
    "        try:\n",
    "            # Extract file key from URL\n",
    "            file_key = url.split('/board/')[1].split('?')[0].split('/')[0]\n",
    "            \n",
    "            # Fetch from FigJam API\n",
    "            headers = {'X-Figma-Token': self.figjam_token}\n",
    "            response = requests.get(\n",
    "                f'https://api.figma.com/v1/files/{file_key}',\n",
    "                headers=headers,\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                return {'error': f'API error: {response.status_code}'}\n",
    "            \n",
    "            data = response.json()\n",
    "            notes_processed = self._extract_figjam_notes(project_id, data, url)\n",
    "            \n",
    "            return {\n",
    "                'notes': notes_processed,\n",
    "                'connections': 0,\n",
    "                'source_url': url\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {'error': str(e)}\n",
    "    \n",
    "    def _extract_figjam_notes(self, project_id, figjam_data, source_url):\n",
    "        \"\"\"Extract and classify notes from FigJam data\"\"\"\n",
    "        notes_count = 0\n",
    "        \n",
    "        def traverse_nodes(node, path=\"\"):\n",
    "            nonlocal notes_count\n",
    "            \n",
    "            # Check if this is a sticky note\n",
    "            if node.get('type') == 'STICKY':\n",
    "                text = node.get('characters', '').strip()\n",
    "                if not text:\n",
    "                    return\n",
    "                \n",
    "                # Extract metadata\n",
    "                author = node.get('authorName', 'Unknown')\n",
    "                color = self._normalize_figjam_color(node.get('backgroundColor', {}))\n",
    "                \n",
    "                # Classify the note\n",
    "                classification = self._classify_note(text, color)\n",
    "                \n",
    "                # Create note object\n",
    "                note = {\n",
    "                    'id': node.get('id', f'note_{notes_count}'),\n",
    "                    'text': text,\n",
    "                    'predicted_type': classification['type'],\n",
    "                    'confidence': classification['confidence'],\n",
    "                    'priority': classification['priority'],\n",
    "                    'color': color,\n",
    "                    'author': author,\n",
    "                    'source': source_url,\n",
    "                    'source_type': 'figjam',\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "                \n",
    "                self.projects[project_id]['notes'].append(note)\n",
    "                notes_count += 1\n",
    "            \n",
    "            # Recurse through children\n",
    "            for child in node.get('children', []):\n",
    "                traverse_nodes(child, f\"{path}/{node.get('name', 'node')}\")\n",
    "        \n",
    "        # Start traversal from document root\n",
    "        traverse_nodes(figjam_data.get('document', {}))\n",
    "        \n",
    "        # Add source\n",
    "        self.projects[project_id]['sources'].append({\n",
    "            'type': 'figjam',\n",
    "            'url': source_url,\n",
    "            'processed': datetime.now().isoformat()\n",
    "        })\n",
    "        \n",
    "        return notes_count\n",
    "    \n",
    "    def _normalize_figjam_color(self, bg_color):\n",
    "        \"\"\"Normalize FigJam color to standard types\"\"\"\n",
    "        if not bg_color:\n",
    "            return 'gray'\n",
    "        \n",
    "        r = bg_color.get('r', 0)\n",
    "        g = bg_color.get('g', 0)\n",
    "        b = bg_color.get('b', 0)\n",
    "        \n",
    "        # Convert to closest standard color\n",
    "        if r > 0.8 and g < 0.3 and b < 0.3:\n",
    "            return 'red'\n",
    "        elif r > 0.8 and g > 0.6 and b < 0.3:\n",
    "            return 'orange'\n",
    "        elif r > 0.8 and g > 0.8 and b < 0.3:\n",
    "            return 'yellow'\n",
    "        elif r < 0.3 and g > 0.6 and b < 0.3:\n",
    "            return 'green'\n",
    "        elif r < 0.4 and g < 0.4 and b > 0.7:\n",
    "            return 'blue'\n",
    "        elif r > 0.6 and g < 0.4 and b > 0.6:\n",
    "            return 'purple'\n",
    "        else:\n",
    "            return 'gray'\n",
    "    \n",
    "    def _classify_note(self, text, color):\n",
    "        \"\"\"Classify note content using enhanced logic\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        # Score each content type\n",
    "        scores = {}\n",
    "        \n",
    "        # PAIN_POINT indicators\n",
    "        pain_words = ['frustrated', 'difficult', 'problem', 'issue', 'struggle', \n",
    "                      'confusing', 'annoying', 'broken', 'error', 'fail', 'hard to']\n",
    "        scores['pain_point'] = sum(1 for w in pain_words if w in text_lower)\n",
    "        \n",
    "        # QUESTION indicators\n",
    "        question_words = ['how', 'what', 'why', 'when', 'where', 'who', 'which', 'could', 'would', 'should']\n",
    "        scores['question'] = sum(1 for w in question_words if w in text_lower)\n",
    "        if '?' in text:\n",
    "            scores['question'] += 2\n",
    "        \n",
    "        # IDEA indicators\n",
    "        idea_words = ['could', 'should', 'what if', 'maybe', 'propose', 'suggest', \n",
    "                      'idea:', 'consider', 'alternative', 'potential']\n",
    "        scores['idea'] = sum(1 for w in idea_words if w in text_lower)\n",
    "        \n",
    "        # QUOTE indicators\n",
    "        if '\"' in text or \"'\" in text or text.startswith('\"') or 'said' in text_lower:\n",
    "            scores['quote'] = 3\n",
    "        else:\n",
    "            scores['quote'] = 0\n",
    "        \n",
    "        # POSITIVE indicators\n",
    "        positive_words = ['love', 'great', 'excellent', 'perfect', 'amazing', \n",
    "                         'wonderful', 'helpful', 'easy', 'intuitive', 'works well']\n",
    "        scores['positive'] = sum(1 for w in positive_words if w in text_lower)\n",
    "        \n",
    "        # Get highest scoring type\n",
    "        if max(scores.values()) > 0:\n",
    "            predicted_type = max(scores, key=scores.get)\n",
    "            confidence = min(0.95, scores[predicted_type] / 5.0)\n",
    "        else:\n",
    "            predicted_type = 'neutral'\n",
    "            confidence = 0.5\n",
    "        \n",
    "        # Determine priority\n",
    "        if predicted_type == 'pain_point' or scores.get('pain_point', 0) >= 2:\n",
    "            priority = 'high'\n",
    "        elif predicted_type in ['question', 'idea']:\n",
    "            priority = 'medium'\n",
    "        else:\n",
    "            priority = 'low'\n",
    "        \n",
    "        return {\n",
    "            'type': predicted_type,\n",
    "            'confidence': confidence,\n",
    "            'priority': priority,\n",
    "            'scores': scores\n",
    "        }\n",
    "    \n",
    "    def ingest_audio_file(self, project_id, file_path):\n",
    "        \"\"\"Process audio file with Whisper\"\"\"\n",
    "        try:\n",
    "            import whisper\n",
    "            model = whisper.load_model(\"base\")\n",
    "            result = model.transcribe(file_path)\n",
    "            \n",
    "            # Process segments as notes\n",
    "            for i, segment in enumerate(result['segments']):\n",
    "                text = segment['text'].strip()\n",
    "                classification = self._classify_note(text, 'none')\n",
    "                \n",
    "                note = {\n",
    "                    'id': f'audio_{i}',\n",
    "                    'text': text,\n",
    "                    'predicted_type': classification['type'],\n",
    "                    'confidence': classification['confidence'],\n",
    "                    'priority': classification['priority'],\n",
    "                    'author': 'Audio Transcript',\n",
    "                    'source': file_path,\n",
    "                    'source_type': 'audio',\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "                \n",
    "                self.projects[project_id]['notes'].append(note)\n",
    "            \n",
    "            self.projects[project_id]['sources'].append({\n",
    "                'type': 'audio',\n",
    "                'file': file_path,\n",
    "                'processed': datetime.now().isoformat()\n",
    "            })\n",
    "            \n",
    "            return {'notes': len(result['segments'])}\n",
    "        except Exception as e:\n",
    "            return {'error': str(e)}\n",
    "    \n",
    "    def ingest_document_file(self, project_id, file_path):\n",
    "        \"\"\"Process document file\"\"\"\n",
    "        try:\n",
    "            if file_path.endswith('.pdf'):\n",
    "                import PyPDF2\n",
    "                with open(file_path, 'rb') as f:\n",
    "                    reader = PyPDF2.PdfReader(f)\n",
    "                    text = \"\"\n",
    "                    for page in reader.pages:\n",
    "                        text += page.extract_text()\n",
    "            elif file_path.endswith('.txt'):\n",
    "                with open(file_path, 'r') as f:\n",
    "                    text = f.read()\n",
    "            else:\n",
    "                return {'error': 'Unsupported format'}\n",
    "            \n",
    "            # Split into paragraphs\n",
    "            paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
    "            \n",
    "            for i, para in enumerate(paragraphs):\n",
    "                classification = self._classify_note(para, 'none')\n",
    "                \n",
    "                note = {\n",
    "                    'id': f'doc_{i}',\n",
    "                    'text': para,\n",
    "                    'predicted_type': classification['type'],\n",
    "                    'confidence': classification['confidence'],\n",
    "                    'priority': classification['priority'],\n",
    "                    'author': 'Document',\n",
    "                    'source': file_path,\n",
    "                    'source_type': 'document',\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "                \n",
    "                self.projects[project_id]['notes'].append(note)\n",
    "            \n",
    "            self.projects[project_id]['sources'].append({\n",
    "                'type': 'document',\n",
    "                'file': file_path,\n",
    "                'processed': datetime.now().isoformat()\n",
    "            })\n",
    "            \n",
    "            return {'notes': len(paragraphs)}\n",
    "        except Exception as e:\n",
    "            return {'error': str(e)}\n",
    "    \n",
    "    def synthesize_project(self, project_id):\n",
    "        \"\"\"Generate comprehensive analysis with ENHANCED theme detection\"\"\"\n",
    "        if project_id not in self.projects:\n",
    "            return {'error': 'Project not found'}\n",
    "        \n",
    "        project = self.projects[project_id]\n",
    "        notes = project['notes']\n",
    "        \n",
    "        if not notes:\n",
    "            return {'error': 'No notes to analyze'}\n",
    "        \n",
    "        # Basic stats\n",
    "        total_notes = len(notes)\n",
    "        contributors = set(n['author'] for n in notes)\n",
    "        \n",
    "        # Content distribution\n",
    "        by_type = defaultdict(list)\n",
    "        for note in notes:\n",
    "            by_type[note['predicted_type']].append(note)\n",
    "        \n",
    "        # Priority distribution\n",
    "        by_priority = defaultdict(list)\n",
    "        for note in notes:\n",
    "            by_priority[note['priority']].append(note)\n",
    "        \n",
    "        # ENHANCED THEME DETECTION using embeddings and clustering\n",
    "        themes = self._detect_themes(notes)\n",
    "        \n",
    "        # High priority action items (deduplicated)\n",
    "        high_priority = by_priority.get('high', [])\n",
    "        action_items = []\n",
    "        seen_texts = set()\n",
    "        \n",
    "        for note in high_priority[:15]:  # Limit to top 15\n",
    "            text_key = note['text'][:50].lower()\n",
    "            if text_key not in seen_texts:\n",
    "                action_items.append({\n",
    "                    'type': note['predicted_type'],\n",
    "                    'text': note['text'],\n",
    "                    'confidence': note['confidence'],\n",
    "                    'author': note['author']\n",
    "                })\n",
    "                seen_texts.add(text_key)\n",
    "        \n",
    "        # Calculate average confidence\n",
    "        avg_confidence = np.mean([n['confidence'] for n in notes])\n",
    "        \n",
    "        return {\n",
    "            'project_name': project['name'],\n",
    "            'generated': datetime.now().isoformat(),\n",
    "            'total_notes': total_notes,\n",
    "            'total_sources': len(project['sources']),\n",
    "            'contributors': len(contributors),\n",
    "            'avg_confidence': avg_confidence,\n",
    "            'by_type': {t: len(notes) for t, notes in by_type.items()},\n",
    "            'by_priority': {p: len(notes) for p, notes in by_priority.items()},\n",
    "            'themes': themes,\n",
    "            'action_items': action_items\n",
    "        }\n",
    "    \n",
    "    def _detect_themes(self, notes, min_cluster_size=3):\n",
    "        \"\"\"Detect themes using TF-IDF and clustering\"\"\"\n",
    "        if len(notes) < min_cluster_size:\n",
    "            return []\n",
    "        \n",
    "        # Extract texts\n",
    "        texts = [n['text'] for n in notes]\n",
    "        \n",
    "        # Use TF-IDF for theme extraction\n",
    "        try:\n",
    "            vectorizer = TfidfVectorizer(\n",
    "                max_features=100,\n",
    "                stop_words='english',\n",
    "                ngram_range=(1, 2),\n",
    "                min_df=2\n",
    "            )\n",
    "            \n",
    "            tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "            feature_names = vectorizer.get_feature_names_out()\n",
    "            \n",
    "            # Get embeddings for clustering\n",
    "            embeddings = self.embedding_model.encode(texts)\n",
    "            \n",
    "            # Cluster similar notes\n",
    "            clustering = DBSCAN(eps=0.5, min_samples=min_cluster_size).fit(embeddings)\n",
    "            \n",
    "            # Extract themes from clusters\n",
    "            themes = []\n",
    "            for cluster_id in set(clustering.labels_):\n",
    "                if cluster_id == -1:  # Skip noise\n",
    "                    continue\n",
    "                \n",
    "                # Get notes in this cluster\n",
    "                cluster_indices = [i for i, label in enumerate(clustering.labels_) if label == cluster_id]\n",
    "                cluster_texts = [texts[i] for i in cluster_indices]\n",
    "                \n",
    "                # Find top terms for this cluster\n",
    "                cluster_tfidf = vectorizer.transform(cluster_texts)\n",
    "                scores = np.asarray(cluster_tfidf.sum(axis=0)).flatten()\n",
    "                top_indices = scores.argsort()[-3:][::-1]\n",
    "                theme_terms = [feature_names[i] for i in top_indices]\n",
    "                \n",
    "                themes.append({\n",
    "                    'name': ' + '.join(theme_terms).title(),\n",
    "                    'frequency': len(cluster_indices),\n",
    "                    'example': cluster_texts[0][:100]\n",
    "                })\n",
    "            \n",
    "            # Sort by frequency\n",
    "            themes.sort(key=lambda x: x['frequency'], reverse=True)\n",
    "            return themes[:5]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Theme detection error: {e}\")\n",
    "            # Fallback: simple keyword frequency\n",
    "            all_text = ' '.join(texts).lower()\n",
    "            words = re.findall(r'\\b\\w{4,}\\b', all_text)\n",
    "            common = Counter(words).most_common(5)\n",
    "            return [{'name': word.title(), 'frequency': count} for word, count in common]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e51c1e73-3ea6-442c-be35-208f65f3f03d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (76586501.py, line 203)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 203\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mfont-size: 12px;\u001b[39m\n                ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# GRADIO UI V3 - ENHANCED ANALYSIS OUTPUT\n",
    "# NOTE: Run the PRISM Brain V3 cell FIRST before this cell\n",
    "# =====================================================\n",
    "\n",
    "import gradio as gr\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üé® Building PRISM UI V3...\")\n",
    "\n",
    "# Reference to Brain V3 (must be initialized in a previous cell)\n",
    "# The brain variable should be available from the previous cell\n",
    "print(\"üì° Connecting to PRISM Brain V3...\")\n",
    "try:\n",
    "    # Test if brain exists by trying to access it\n",
    "    test = brain\n",
    "    print(\"‚úÖ Connected to Brain V3\")\n",
    "except NameError:\n",
    "    raise RuntimeError(\"‚ùå Brain V3 not found! Run the Brain V3 initialization cell first.\")\n",
    "\n",
    "\n",
    "current_project_id = None\n",
    "\n",
    "# =====================================================\n",
    "# UI FUNCTIONS\n",
    "# =====================================================\n",
    "\n",
    "def create_project(name):\n",
    "    global current_project_id\n",
    "    if not name:\n",
    "        return \"‚ùå Enter project name\"\n",
    "    current_project_id = brain.create_project(name)\n",
    "    return f\"‚úÖ Project created: {name}\\nüìã ID: {current_project_id}\"\n",
    "\n",
    "def upload_figjam(url):\n",
    "    global current_project_id\n",
    "    if not current_project_id:\n",
    "        return \"‚ùå Create project first\"\n",
    "    \n",
    "    result = brain.ingest_figjam_url(current_project_id, url)\n",
    "    if 'error' in result:\n",
    "        return f\"‚ùå {result['error']}\"\n",
    "    return f\"‚úÖ FigJam board analyzed!\\nüìä Notes processed: {result['notes']}\\nüîó Source: {result['source_url']}\"\n",
    "\n",
    "def upload_audio(file):\n",
    "    global current_project_id\n",
    "    if not current_project_id:\n",
    "        return \"‚ùå Create project first\"\n",
    "    if not file:\n",
    "        return \"‚ùå No file\"\n",
    "    \n",
    "    result = brain.ingest_audio_file(current_project_id, file.name)\n",
    "    if 'error' in result:\n",
    "        return f\"‚ùå {result['error']}\"\n",
    "    return f\"‚úÖ Audio transcribed!\\nüìä Segments analyzed: {result['notes']}\"\n",
    "\n",
    "def upload_doc(file):\n",
    "    global current_project_id\n",
    "    if not current_project_id:\n",
    "        return \"‚ùå Create project first\"\n",
    "    if not file:\n",
    "        return \"‚ùå No file\"\n",
    "    \n",
    "    result = brain.ingest_document_file(current_project_id, file.name)\n",
    "    if 'error' in result:\n",
    "        return f\"‚ùå {result['error']}\"\n",
    "    return f\"‚úÖ Document analyzed!\\nüìä Sections processed: {result['notes']}\"\n",
    "\n",
    "def analyze():\n",
    "    global current_project_id\n",
    "    if not current_project_id:\n",
    "        return \"‚ùå Create project first\"\n",
    "    \n",
    "    s = brain.synthesize_project(current_project_id)\n",
    "    \n",
    "    if 'error' in s:\n",
    "        return f\"‚ùå {s['error']}\"\n",
    "    \n",
    "    # Format comprehensive research debrief\n",
    "    exec_sum = s['executive_summary']\n",
    "    \n",
    "    output = f\"\"\"‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë                     PRISM RESEARCH DEBRIEF REPORT                             ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "PROJECT          {s['project_name']}\n",
    "GENERATED        {s['generated']}\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "‚ñà EXECUTIVE SUMMARY\n",
    "\n",
    "Research Focus:     {exec_sum['focus_area']}\n",
    "Research Type:      {exec_sum['research_type']}\n",
    "Participants:       {exec_sum['participant_count']} contributor(s)\n",
    "Data Points:        {s['total_notes']} notes from {s['total_sources']} source(s)\n",
    "\n",
    "Primary Concern:\n",
    "  \"{exec_sum['main_concern'][:200]}\"\n",
    "\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "‚ñà KEY INSIGHTS\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    # Display key insights\n",
    "    if s['key_insights']:\n",
    "        for i, insight in enumerate(s['key_insights'], 1):\n",
    "            if insight['type'] == 'pain_point':\n",
    "                output += f\"  üî¥ PAIN POINT (mentioned {insight['frequency']}x)\\n\"\n",
    "            else:\n",
    "                output += f\"  üí° {insight['type'].upper()}\\n\"\n",
    "            output += f\"     {insight['insight']}\\n\\n\"\n",
    "    else:\n",
    "        output += \"  No major insights detected\\n\"\n",
    "    \n",
    "    output += f\"\"\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "‚ñà THEMATIC ANALYSIS\n",
    "\n",
    "\"\"\"\n",
    "    if s['themes']:\n",
    "        for i, theme in enumerate(s['themes'], 1):\n",
    "            bar_length = min(int(theme['frequency'] / 3), 40)\n",
    "            bar = '‚ñì' * bar_length\n",
    "            output += f\"  {i}. {theme['name']}\\n\"\n",
    "            output += f\"     Frequency: {theme['frequency']} mentions {bar}\\n\"\n",
    "            if 'example' in theme:\n",
    "                example = theme['example'][:80] + '...' if len(theme['example']) > 80 else theme['example']\n",
    "                output += f\"     Example: \\\"{example}\\\"\\n\"\n",
    "            output += \"\\n\"\n",
    "    else:\n",
    "        output += \"  No themes detected (need more data)\\n\"\n",
    "    \n",
    "    output += f\"\"\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "‚ñà USER PAIN POINTS & CHALLENGES\n",
    "\n",
    "\"\"\"\n",
    "    if s['action_items']:\n",
    "        for i, item in enumerate(s['action_items'][:8], 1):\n",
    "            output += f\"  {i}. {item['text']}\\n\"\n",
    "            output += f\"     ‚Äî {item['author']} (confidence: {item['confidence']*100:.0f}%)\\n\\n\"\n",
    "    else:\n",
    "        output += \"  No critical pain points identified\\n\"\n",
    "    \n",
    "    output += f\"\"\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "# BUILD UI\n",
    "with gr.Blocks(title=\"PRISM V3\") as demo:\n",
    "    gr.Markdown(\"# PRISM V3 - Enhanced Research Synthesis\\n### Multi-Modal AI Analysis with Improved Classification\")\n",
    "    \n",
    "    gr.Markdown(\"## 1. Create Project\")\n",
    "    with gr.Row():\n",
    "        project_name = gr.Textbox(label=\"Project Name\", placeholder=\"Enter project name...\")\n",
    "        create_btn = gr.Button(\"Create\", variant=\"primary\")\n",
    "    create_status = gr.Textbox(label=\"Status\", lines=2)\n",
    "    \n",
    "    gr.Markdown(\"---\")\n",
    "    gr.Markdown(\"## 2. Upload Data Sources\")\n",
    "    \n",
    "    with gr.Tab(\"üìã FigJam Board\"):\n",
    "        figjam_url = gr.Textbox(\n",
    "            label=\"FigJam Board URL\",\n",
    "            placeholder=\"https://www.figma.com/board/...\"\n",
    "        )\n",
    "        figjam_btn = gr.Button(\"Analyze Board\", variant=\"primary\")\n",
    "        figjam_status = gr.Textbox(label=\"Status\", lines=3)\n",
    "    \n",
    "    with gr.Tab(\"üéôÔ∏è Audio File\"):\n",
    "        audio_file = gr.File(label=\"Audio (.mp3, .wav, .mov)\")\n",
    "        audio_btn = gr.Button(\"Process Audio\", variant=\"primary\")\n",
    "        audio_status = gr.Textbox(label=\"Status\", lines=3)\n",
    "    \n",
    "    with gr.Tab(\"üìÑ Document\"):\n",
    "        doc_file = gr.File(label=\"Document (.pdf, .txt)\")\n",
    "        doc_btn = gr.Button(\"Process Document\", variant=\"primary\")\n",
    "        doc_status = gr.Textbox(label=\"Status\", lines=3)\n",
    "    \n",
    "    gr.Markdown(\"---\")\n",
    "    gr.Markdown(\"## 3. Generate Analysis\")\n",
    "    \n",
    "    analyze_btn = gr.Button(\"üîç GENERATE SYNTHESIS REPORT\", variant=\"primary\", size=\"lg\")\n",
    "    \n",
    "    gr.Markdown(\"### Analysis Output\")\n",
    "    analysis_output = gr.Textbox(\n",
    "        label=\"Synthesis Report\",\n",
    "        lines=35,\n",
    "        show_copy_button=True,\n",
    "        elem_classes=[\"monospace\"]\n",
    "    )\n",
    "    \n",
    "    # Wire up events\n",
    "    create_btn.click(create_project, [project_name], [create_status])\n",
    "    figjam_btn.click(upload_figjam, [figjam_url], [figjam_status])\n",
    "    audio_btn.click(upload_audio, [audio_file], [audio_status])\n",
    "    doc_btn.click(upload_doc, [doc_file], [doc_status])\n",
    "    analyze_btn.click(analyze, [], [analysis_output])\n",
    "    \n",
    "    # Add custom CSS\n",
    "    demo.css = \"\"\"\n",
    "    .monospace textarea {\n",
    "        font-family: 'Courier New', monospace;\n",
    "        font-size: 12px;\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "print(\"üöÄ Launching PRISM V3...\")\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "def15819-7dd9-4eaf-9e48-682a4fd4ec86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé® Building PRISM UI V3...\n",
      "üì° Connecting to PRISM Brain V3...\n",
      "‚úÖ Connected to Brain V3\n",
      "üöÄ Launching PRISM V3...\n",
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* Running on public URL: https://739022d040a4b5b049.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://739022d040a4b5b049.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theme detection error: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/gradio/queueing.py\", line 759, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/gradio/route_utils.py\", line 354, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/gradio/blocks.py\", line 2116, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/gradio/blocks.py\", line 1623, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/gradio/utils.py\", line 915, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1173/1773242001.py\", line 80, in analyze\n",
      "    exec_sum = s['executive_summary']\n",
      "               ~^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'executive_summary'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theme detection error: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/gradio/queueing.py\", line 759, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/gradio/route_utils.py\", line 354, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/gradio/blocks.py\", line 2116, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/gradio/blocks.py\", line 1623, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/gradio/utils.py\", line 915, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1173/1773242001.py\", line 80, in analyze\n",
      "    exec_sum = s['executive_summary']\n",
      "               ~^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'executive_summary'\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# GRADIO UI V3 - ENHANCED ANALYSIS OUTPUT\n",
    "# NOTE: Run the PRISM Brain V3 cell FIRST before this cell\n",
    "# =====================================================\n",
    "\n",
    "import gradio as gr\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üé® Building PRISM UI V3...\")\n",
    "\n",
    "# Reference to Brain V3 (must be initialized in a previous cell)\n",
    "# The brain variable should be available from the previous cell\n",
    "print(\"üì° Connecting to PRISM Brain V3...\")\n",
    "try:\n",
    "    # Test if brain exists by trying to access it\n",
    "    test = brain\n",
    "    print(\"‚úÖ Connected to Brain V3\")\n",
    "except NameError:\n",
    "    raise RuntimeError(\"‚ùå Brain V3 not found! Run the Brain V3 initialization cell first.\")\n",
    "\n",
    "\n",
    "current_project_id = None\n",
    "\n",
    "# =====================================================\n",
    "# UI FUNCTIONS\n",
    "# =====================================================\n",
    "\n",
    "def create_project(name):\n",
    "    global current_project_id\n",
    "    if not name:\n",
    "        return \"‚ùå Enter project name\"\n",
    "    current_project_id = brain.create_project(name)\n",
    "    return f\"‚úÖ Project created: {name}\\nüìã ID: {current_project_id}\"\n",
    "\n",
    "def upload_figjam(url):\n",
    "    global current_project_id\n",
    "    if not current_project_id:\n",
    "        return \"‚ùå Create project first\"\n",
    "    \n",
    "    result = brain.ingest_figjam_url(current_project_id, url)\n",
    "    if 'error' in result:\n",
    "        return f\"‚ùå {result['error']}\"\n",
    "    return f\"‚úÖ FigJam board analyzed!\\nüìä Notes processed: {result['notes']}\\nüîó Source: {result['source_url']}\"\n",
    "\n",
    "def upload_audio(file):\n",
    "    global current_project_id\n",
    "    if not current_project_id:\n",
    "        return \"‚ùå Create project first\"\n",
    "    if not file:\n",
    "        return \"‚ùå No file\"\n",
    "    \n",
    "    result = brain.ingest_audio_file(current_project_id, file.name)\n",
    "    if 'error' in result:\n",
    "        return f\"‚ùå {result['error']}\"\n",
    "    return f\"‚úÖ Audio transcribed!\\nüìä Segments analyzed: {result['notes']}\"\n",
    "\n",
    "def upload_doc(file):\n",
    "    global current_project_id\n",
    "    if not current_project_id:\n",
    "        return \"‚ùå Create project first\"\n",
    "    if not file:\n",
    "        return \"‚ùå No file\"\n",
    "    \n",
    "    result = brain.ingest_document_file(current_project_id, file.name)\n",
    "    if 'error' in result:\n",
    "        return f\"‚ùå {result['error']}\"\n",
    "    return f\"‚úÖ Document analyzed!\\nüìä Sections processed: {result['notes']}\"\n",
    "\n",
    "def analyze():\n",
    "    global current_project_id\n",
    "    if not current_project_id:\n",
    "        return \"‚ùå Create project first\"\n",
    "    \n",
    "    s = brain.synthesize_project(current_project_id)\n",
    "    \n",
    "    if 'error' in s:\n",
    "        return f\"‚ùå {s['error']}\"\n",
    "    \n",
    "    # Format comprehensive research debrief\n",
    "    exec_sum = s['executive_summary']\n",
    "    \n",
    "    output = f\"\"\"‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë                     PRISM RESEARCH DEBRIEF REPORT                             ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "PROJECT          {s['project_name']}\n",
    "GENERATED        {s['generated']}\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "‚ñà EXECUTIVE SUMMARY\n",
    "\n",
    "Research Focus:     {exec_sum['focus_area']}\n",
    "Research Type:      {exec_sum['research_type']}\n",
    "Participants:       {exec_sum['participant_count']} contributor(s)\n",
    "Data Points:        {s['total_notes']} notes from {s['total_sources']} source(s)\n",
    "\n",
    "Primary Concern:\n",
    "  \"{exec_sum['main_concern'][:200]}\"\n",
    "\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "‚ñà KEY INSIGHTS\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    # Display key insights\n",
    "    if s['key_insights']:\n",
    "        for i, insight in enumerate(s['key_insights'], 1):\n",
    "            if insight['type'] == 'pain_point':\n",
    "                output += f\"  üî¥ PAIN POINT (mentioned {insight['frequency']}x)\\n\"\n",
    "            else:\n",
    "                output += f\"  üí° {insight['type'].upper()}\\n\"\n",
    "            output += f\"     {insight['insight']}\\n\\n\"\n",
    "    else:\n",
    "        output += \"  No major insights detected\\n\"\n",
    "    \n",
    "    output += f\"\"\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "‚ñà THEMATIC ANALYSIS\n",
    "\n",
    "\"\"\"\n",
    "    if s['themes']:\n",
    "        for i, theme in enumerate(s['themes'], 1):\n",
    "            bar_length = min(int(theme['frequency'] / 3), 40)\n",
    "            bar = '‚ñì' * bar_length\n",
    "            output += f\"  {i}. {theme['name']}\\n\"\n",
    "            output += f\"     Frequency: {theme['frequency']} mentions {bar}\\n\"\n",
    "            if 'example' in theme:\n",
    "                example = theme['example'][:80] + '...' if len(theme['example']) > 80 else theme['example']\n",
    "                output += f\"     Example: \\\"{example}\\\"\\n\"\n",
    "            output += \"\\n\"\n",
    "    else:\n",
    "        output += \"  No themes detected (need more data)\\n\"\n",
    "    \n",
    "    output += f\"\"\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "‚ñà USER PAIN POINTS & CHALLENGES\n",
    "\n",
    "\"\"\"\n",
    "    if s['action_items']:\n",
    "        for i, item in enumerate(s['action_items'][:8], 1):\n",
    "            output += f\"  {i}. {item['text']}\\n\"\n",
    "            output += f\"     ‚Äî {item['author']} (confidence: {item['confidence']*100:.0f}%)\\n\\n\"\n",
    "    else:\n",
    "        output += \"  No critical pain points identified\\n\"\n",
    "    \n",
    "    output += f\"\"\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "‚ñà KEY QUESTIONS RAISED\n",
    "\n",
    "\"\"\"\n",
    "    if s['questions']:\n",
    "        for i, q in enumerate(s['questions'][:5], 1):\n",
    "            text = q['text'][:150] + '...' if len(q['text']) > 150 else q['text']\n",
    "            output += f\"  {i}. {text}\\n\"\n",
    "            output += f\"     ‚Äî {q['author']}\\n\\n\"\n",
    "    else:\n",
    "        output += \"  No questions documented\\n\"\n",
    "    \n",
    "    output += f\"\"\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "‚ñà IDEAS & OPPORTUNITIES\n",
    "\n",
    "\"\"\"\n",
    "    if s['ideas']:\n",
    "        for i, idea in enumerate(s['ideas'][:5], 1):\n",
    "            text = idea['text'][:150] + '...' if len(idea['text']) > 150 else idea['text']\n",
    "            output += f\"  {i}. {text}\\n\"\n",
    "            output += f\"     ‚Äî {idea['author']}\\n\\n\"\n",
    "    else:\n",
    "        output += \"  No ideas captured\\n\"\n",
    "    \n",
    "    output += f\"\"\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "‚ñà SUPPORTING QUOTES\n",
    "\n",
    "\"\"\"\n",
    "    if s['quotes']:\n",
    "        for i, quote in enumerate(s['quotes'][:5], 1):\n",
    "            text = quote['text'][:150] + '...' if len(quote['text']) > 150 else quote['text']\n",
    "            output += f\"  {i}. \\\"{text}\\\"\\n\"\n",
    "            output += f\"     ‚Äî {quote['author']}\\n\\n\"\n",
    "    else:\n",
    "        output += \"  No direct quotes captured\\n\"\n",
    "    \n",
    "    output += f\"\"\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "‚ñà DATA BREAKDOWN\n",
    "\n",
    "Content Distribution:\n",
    "\"\"\"\n",
    "    \n",
    "    # Sort by count and create bar chart\n",
    "    type_counts = sorted(s['by_type'].items(), key=lambda x: x[1], reverse=True)\n",
    "    max_count = max([c for _, c in type_counts]) if type_counts else 1\n",
    "    \n",
    "    for content_type, count in type_counts:\n",
    "        percentage = (count / s['total_notes']) * 100\n",
    "        bar_length = int((count / max_count) * 30)\n",
    "        bar = '‚ñà' * bar_length\n",
    "        output += f\"  {content_type.upper():15} {count:4} {bar} {percentage:.1f}%\\n\"\n",
    "    \n",
    "    output += f\"\"\"\n",
    "Priority Distribution:\n",
    "\"\"\"\n",
    "    for priority in ['high', 'medium', 'low']:\n",
    "        count = s['by_priority'].get(priority, 0)\n",
    "        percentage = (count / s['total_notes']) * 100 if s['total_notes'] > 0 else 0\n",
    "        output += f\"  {priority.upper():15} {count:4} ({percentage:.1f}%)\\n\"\n",
    "    \n",
    "    output += f\"\"\"\n",
    "Analysis Confidence: {s['avg_confidence']*100:.1f}%\n",
    "\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "                              END OF REPORT\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\"\"\"\n",
    "    \n",
    "    return output\n",
    "\n",
    "# BUILD UI\n",
    "with gr.Blocks(title=\"PRISM V3\") as demo:\n",
    "    gr.Markdown(\"# PRISM V3 - Enhanced Research Synthesis\\n### Multi-Modal AI Analysis with Improved Classification\")\n",
    "    \n",
    "    gr.Markdown(\"## 1. Create Project\")\n",
    "    with gr.Row():\n",
    "        project_name = gr.Textbox(label=\"Project Name\", placeholder=\"Enter project name...\")\n",
    "        create_btn = gr.Button(\"Create\", variant=\"primary\")\n",
    "    create_status = gr.Textbox(label=\"Status\", lines=2)\n",
    "    \n",
    "    gr.Markdown(\"---\")\n",
    "    gr.Markdown(\"## 2. Upload Data Sources\")\n",
    "    \n",
    "    with gr.Tab(\"üìã FigJam Board\"):\n",
    "        figjam_url = gr.Textbox(\n",
    "            label=\"FigJam Board URL\",\n",
    "            placeholder=\"https://www.figma.com/board/...\"\n",
    "        )\n",
    "        figjam_btn = gr.Button(\"Analyze Board\", variant=\"primary\")\n",
    "        figjam_status = gr.Textbox(label=\"Status\", lines=3)\n",
    "    \n",
    "    with gr.Tab(\"üéôÔ∏è Audio File\"):\n",
    "        audio_file = gr.File(label=\"Audio (.mp3, .wav, .mov)\")\n",
    "        audio_btn = gr.Button(\"Process Audio\", variant=\"primary\")\n",
    "        audio_status = gr.Textbox(label=\"Status\", lines=3)\n",
    "    \n",
    "    with gr.Tab(\"üìÑ Document\"):\n",
    "        doc_file = gr.File(label=\"Document (.pdf, .txt)\")\n",
    "        doc_btn = gr.Button(\"Process Document\", variant=\"primary\")\n",
    "        doc_status = gr.Textbox(label=\"Status\", lines=3)\n",
    "    \n",
    "    gr.Markdown(\"---\")\n",
    "    gr.Markdown(\"## 3. Generate Analysis\")\n",
    "    \n",
    "    analyze_btn = gr.Button(\"üîç GENERATE SYNTHESIS REPORT\", variant=\"primary\", size=\"lg\")\n",
    "    \n",
    "    gr.Markdown(\"### Analysis Output\")\n",
    "    analysis_output = gr.Textbox(\n",
    "        label=\"Synthesis Report\",\n",
    "        lines=35,\n",
    "        show_copy_button=True,\n",
    "        elem_classes=[\"monospace\"]\n",
    "    )\n",
    "    \n",
    "    # Wire up events\n",
    "    create_btn.click(create_project, [project_name], [create_status])\n",
    "    figjam_btn.click(upload_figjam, [figjam_url], [figjam_status])\n",
    "    audio_btn.click(upload_audio, [audio_file], [audio_status])\n",
    "    doc_btn.click(upload_doc, [doc_file], [doc_status])\n",
    "    analyze_btn.click(analyze, [], [analysis_output])\n",
    "\n",
    "print(\"üöÄ Launching PRISM V3...\")\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a1dbd95-141e-43e2-82a5-c81ef5ed0701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Loading training data...\n",
      "‚úÖ Loaded 10000 boards\n",
      "üìö Loading training data...\n",
      "ü§ñ Loading embedding model...\n",
      "‚úÖ PRISM Brain V3 ready!\n",
      "‚úÖ Brain V3 initialized!\n",
      "Brain type: <class '__main__.PRISMBrainV3'>\n",
      "Brain has 0 projects\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "import json\n",
    "\n",
    "print(\"üìö Loading training data...\")\n",
    "with open('/home/jovyan/local/DeepLearning/synthetic_data/full_10k/training_data.json', 'r') as f:\n",
    "    training_data = json.load(f)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(training_data)} boards\")\n",
    "\n",
    "# Your FigJam token\n",
    "figjam_token = \"figd_YP-yLbvxZ0jOVR9C54bCPveiHdkFB3uZD7hKQKDF\"\n",
    "\n",
    "# Create Brain V3 instance - passing empty list to skip pattern learning\n",
    "brain = PRISMBrainV3([], figjam_token)\n",
    "brain.training_data = training_data\n",
    "\n",
    "# Force CPU usage for embeddings to avoid CUDA errors\n",
    "brain.embedding_model = brain.embedding_model.to('cpu')\n",
    "\n",
    "print(\"‚úÖ Brain V3 initialized!\")\n",
    "print(f\"Brain type: {type(brain)}\")\n",
    "print(f\"Brain has {len(brain.projects)} projects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adb7eebd-2f23-462a-8888-e3da81866500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé® Building PRISM UI...\n",
      "‚úÖ Connected to Brain V3\n",
      "üöÄ Launching PRISM V3...\n",
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* Running on public URL: https://a4f1a05455c8b8c3ec.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://a4f1a05455c8b8c3ec.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =====================================================\n",
    "# GRADIO UI FOR PRISM BRAIN V3\n",
    "# =====================================================\n",
    "\n",
    "import gradio as gr\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üé® Building PRISM UI...\")\n",
    "\n",
    "# Check brain exists\n",
    "try:\n",
    "    test = brain\n",
    "    print(\"‚úÖ Connected to Brain V3\")\n",
    "except NameError:\n",
    "    raise RuntimeError(\"‚ùå Brain V3 not found! Run the Brain V3 initialization cell first.\")\n",
    "\n",
    "current_project_id = None\n",
    "\n",
    "# =====================================================\n",
    "# UI FUNCTIONS\n",
    "# =====================================================\n",
    "\n",
    "def create_project(name):\n",
    "    global current_project_id\n",
    "    if not name:\n",
    "        return \"‚ùå Enter project name\"\n",
    "    current_project_id = brain.create_project(name)\n",
    "    return f\"‚úÖ Project created: {name}\\nüìã ID: {current_project_id}\"\n",
    "\n",
    "def upload_figjam(url):\n",
    "    global current_project_id\n",
    "    if not current_project_id:\n",
    "        return \"‚ùå Create project first\"\n",
    "    \n",
    "    result = brain.ingest_figjam_url(current_project_id, url)\n",
    "    if 'error' in result:\n",
    "        return f\"‚ùå {result['error']}\"\n",
    "    return f\"‚úÖ FigJam board analyzed!\\nüìä Notes processed: {result['notes']}\\nüîó Source: {result['source_url']}\"\n",
    "\n",
    "def upload_audio(file):\n",
    "    global current_project_id\n",
    "    if not current_project_id:\n",
    "        return \"‚ùå Create project first\"\n",
    "    if not file:\n",
    "        return \"‚ùå No file\"\n",
    "    \n",
    "    result = brain.ingest_audio_file(current_project_id, file.name)\n",
    "    if 'error' in result:\n",
    "        return f\"‚ùå {result['error']}\"\n",
    "    return f\"‚úÖ Audio transcribed!\\nüìä Segments analyzed: {result['notes']}\"\n",
    "\n",
    "def upload_doc(file):\n",
    "    global current_project_id\n",
    "    if not current_project_id:\n",
    "        return \"‚ùå Create project first\"\n",
    "    if not file:\n",
    "        return \"‚ùå No file\"\n",
    "    \n",
    "    result = brain.ingest_document_file(current_project_id, file.name)\n",
    "    if 'error' in result:\n",
    "        return f\"‚ùå {result['error']}\"\n",
    "    return f\"‚úÖ Document analyzed!\\nüìä Sections processed: {result['notes']}\"\n",
    "\n",
    "def analyze():\n",
    "    global current_project_id\n",
    "    if not current_project_id:\n",
    "        return \"‚ùå Create project first\"\n",
    "    \n",
    "    try:\n",
    "        s = brain.synthesize_project(current_project_id)\n",
    "        \n",
    "        if 'error' in s:\n",
    "            return f\"‚ùå {s['error']}\"\n",
    "        \n",
    "        # Format comprehensive research debrief\n",
    "        exec_sum = s.get('executive_summary', {})\n",
    "        \n",
    "        output = f\"\"\"‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë                     PRISM RESEARCH DEBRIEF REPORT                             ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "PROJECT          {s['project_name']}\n",
    "GENERATED        {s['generated']}\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "‚ñà EXECUTIVE SUMMARY\n",
    "\n",
    "Research Focus:     {exec_sum.get('focus_area', 'Unknown')}\n",
    "Research Type:      {exec_sum.get('research_type', 'Unknown')}\n",
    "Participants:       {exec_sum.get('participant_count', 0)} contributor(s)\n",
    "Data Points:        {s['total_notes']} notes from {s['total_sources']} source(s)\n",
    "\n",
    "Primary Concern:\n",
    "  \"{exec_sum.get('main_concern', 'No concerns identified')[:200]}\"\n",
    "\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "‚ñà KEY INSIGHTS\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        # Display key insights\n",
    "        if s.get('key_insights'):\n",
    "            for i, insight in enumerate(s['key_insights'], 1):\n",
    "                if insight['type'] == 'pain_point':\n",
    "                    output += f\"  üî¥ PAIN POINT (mentioned {insight['frequency']}x)\\n\"\n",
    "                else:\n",
    "                    output += f\"  üí° {insight['type'].upper()}\\n\"\n",
    "                output += f\"     {insight['insight']}\\n\\n\"\n",
    "        else:\n",
    "            output += \"  No major insights detected\\n\"\n",
    "        \n",
    "        output += f\"\"\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "‚ñà THEMATIC ANALYSIS\n",
    "\n",
    "\"\"\"\n",
    "        if s.get('themes'):\n",
    "            for i, theme in enumerate(s['themes'], 1):\n",
    "                bar_length = min(int(theme['frequency'] / 3), 40)\n",
    "                bar = '‚ñì' * bar_length\n",
    "                output += f\"  {i}. {theme['name']}\\n\"\n",
    "                output += f\"     Frequency: {theme['frequency']} mentions {bar}\\n\"\n",
    "                if 'example' in theme:\n",
    "                    example = theme['example'][:80] + '...' if len(theme['example']) > 80 else theme['example']\n",
    "                    output += f\"     Example: \\\"{example}\\\"\\n\"\n",
    "                output += \"\\n\"\n",
    "        else:\n",
    "            output += \"  No themes detected (need more data)\\n\"\n",
    "        \n",
    "        output += f\"\"\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "‚ñà USER PAIN POINTS & CHALLENGES\n",
    "\n",
    "\"\"\"\n",
    "        if s.get('action_items'):\n",
    "            for i, item in enumerate(s['action_items'][:8], 1):\n",
    "                output += f\"  {i}. {item['text']}\\n\"\n",
    "                output += f\"     ‚Äî {item['author']} (confidence: {item['confidence']*100:.0f}%)\\n\\n\"\n",
    "        else:\n",
    "            output += \"  No critical pain points identified\\n\"\n",
    "        \n",
    "        output += f\"\"\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "‚ñà KEY QUESTIONS RAISED\n",
    "\n",
    "\"\"\"\n",
    "        if s.get('questions'):\n",
    "            for i, q in enumerate(s['questions'][:5], 1):\n",
    "                text = q['text'][:150] + '...' if len(q['text']) > 150 else q['text']\n",
    "                output += f\"  {i}. {text}\\n\"\n",
    "                output += f\"     ‚Äî {q['author']}\\n\\n\"\n",
    "        else:\n",
    "            output += \"  No questions documented\\n\"\n",
    "        \n",
    "        output += f\"\"\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "‚ñà IDEAS & OPPORTUNITIES\n",
    "\n",
    "\"\"\"\n",
    "        if s.get('ideas'):\n",
    "            for i, idea in enumerate(s['ideas'][:5], 1):\n",
    "                text = idea['text'][:150] + '...' if len(idea['text']) > 150 else idea['text']\n",
    "                output += f\"  {i}. {text}\\n\"\n",
    "                output += f\"     ‚Äî {idea['author']}\\n\\n\"\n",
    "        else:\n",
    "            output += \"  No ideas captured\\n\"\n",
    "        \n",
    "        output += f\"\"\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "‚ñà SUPPORTING QUOTES\n",
    "\n",
    "\"\"\"\n",
    "        if s.get('quotes'):\n",
    "            for i, quote in enumerate(s['quotes'][:5], 1):\n",
    "                text = quote['text'][:150] + '...' if len(quote['text']) > 150 else quote['text']\n",
    "                output += f\"  {i}. \\\"{text}\\\"\\n\"\n",
    "                output += f\"     ‚Äî {quote['author']}\\n\\n\"\n",
    "        else:\n",
    "            output += \"  No direct quotes captured\\n\"\n",
    "        \n",
    "        output += f\"\"\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "‚ñà DATA BREAKDOWN\n",
    "\n",
    "Content Distribution:\n",
    "\"\"\"\n",
    "        \n",
    "        # Sort by count and create bar chart\n",
    "        type_counts = sorted(s['by_type'].items(), key=lambda x: x[1], reverse=True)\n",
    "        max_count = max([c for _, c in type_counts]) if type_counts else 1\n",
    "        \n",
    "        for content_type, count in type_counts:\n",
    "            percentage = (count / s['total_notes']) * 100\n",
    "            bar_length = int((count / max_count) * 30)\n",
    "            bar = '‚ñà' * bar_length\n",
    "            output += f\"  {content_type.upper():15} {count:4} {bar} {percentage:.1f}%\\n\"\n",
    "        \n",
    "        output += f\"\"\"\n",
    "Priority Distribution:\n",
    "\"\"\"\n",
    "        for priority in ['high', 'medium', 'low']:\n",
    "            count = s['by_priority'].get(priority, 0)\n",
    "            percentage = (count / s['total_notes']) * 100 if s['total_notes'] > 0 else 0\n",
    "            output += f\"  {priority.upper():15} {count:4} ({percentage:.1f}%)\\n\"\n",
    "        \n",
    "        output += f\"\"\"\n",
    "Analysis Confidence: {s['avg_confidence']*100:.1f}%\n",
    "\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "                              END OF REPORT\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\"\"\"\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error generating report: {str(e)}\\n\\nPlease check the console for details.\"\n",
    "\n",
    "# BUILD UI\n",
    "with gr.Blocks(title=\"PRISM V3\") as demo:\n",
    "    gr.Markdown(\"# PRISM V3 - Enhanced Research Synthesis\\n### Multi-Modal AI Analysis with Comprehensive Debriefs\")\n",
    "    \n",
    "    gr.Markdown(\"## 1. Create Project\")\n",
    "    with gr.Row():\n",
    "        project_name = gr.Textbox(label=\"Project Name\", placeholder=\"Enter project name...\")\n",
    "        create_btn = gr.Button(\"Create\", variant=\"primary\")\n",
    "    create_status = gr.Textbox(label=\"Status\", lines=2)\n",
    "    \n",
    "    gr.Markdown(\"---\")\n",
    "    gr.Markdown(\"## 2. Upload Data Sources\")\n",
    "    \n",
    "    with gr.Tab(\"üìã FigJam Board\"):\n",
    "        figjam_url = gr.Textbox(\n",
    "            label=\"FigJam Board URL\",\n",
    "            placeholder=\"https://www.figma.com/board/...\"\n",
    "        )\n",
    "        figjam_btn = gr.Button(\"Analyze Board\", variant=\"primary\")\n",
    "        figjam_status = gr.Textbox(label=\"Status\", lines=3)\n",
    "    \n",
    "    with gr.Tab(\"üéôÔ∏è Audio File\"):\n",
    "        audio_file = gr.File(label=\"Audio (.mp3, .wav, .mov)\")\n",
    "        audio_btn = gr.Button(\"Process Audio\", variant=\"primary\")\n",
    "        audio_status = gr.Textbox(label=\"Status\", lines=3)\n",
    "    \n",
    "    with gr.Tab(\"üìÑ Document\"):\n",
    "        doc_file = gr.File(label=\"Document (.pdf, .txt)\")\n",
    "        doc_btn = gr.Button(\"Process Document\", variant=\"primary\")\n",
    "        doc_status = gr.Textbox(label=\"Status\", lines=3)\n",
    "    \n",
    "    gr.Markdown(\"---\")\n",
    "    gr.Markdown(\"## 3. Generate Analysis\")\n",
    "    \n",
    "    analyze_btn = gr.Button(\"üîç GENERATE RESEARCH DEBRIEF\", variant=\"primary\", size=\"lg\")\n",
    "    \n",
    "    gr.Markdown(\"### Research Debrief Report\")\n",
    "    analysis_output = gr.Textbox(\n",
    "        label=\"Comprehensive Analysis\",\n",
    "        lines=40,\n",
    "        show_copy_button=True\n",
    "    )\n",
    "    \n",
    "    # Wire up events\n",
    "    create_btn.click(create_project, [project_name], [create_status])\n",
    "    figjam_btn.click(upload_figjam, [figjam_url], [figjam_status])\n",
    "    audio_btn.click(upload_audio, [audio_file], [audio_status])\n",
    "    doc_btn.click(upload_doc, [doc_file], [doc_status])\n",
    "    analyze_btn.click(analyze, [], [analysis_output])\n",
    "\n",
    "print(\"üöÄ Launching PRISM V3...\")\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959c0312-4a46-49c3-af9a-94e543d1bff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
